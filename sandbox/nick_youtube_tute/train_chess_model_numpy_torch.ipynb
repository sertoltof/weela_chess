{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4244d1b4-83a1-489f-89a3-18d6842c64b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deed268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11eb5a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e21f5727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fc89010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chess import Board\n",
    "from chess import pgn\n",
    "from chess.pgn import Game\n",
    "import chess.engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb652c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-07 19:41:54.409162: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741394514.428767  186521 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741394514.434547  186521 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-07 19:41:54.456405: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from weela_chess.data_io.convert_pgn_to_np import board_to_matrix\n",
    "from weela_chess.chess_utils.all_possible_moves import all_uci_codes_to_moves\n",
    "from sandbox.pytorch_mnist.pytorch_mnist_main import pytorch_train, pytorch_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04370d2",
   "metadata": {},
   "source": [
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4117a144",
   "metadata": {},
   "source": [
    "# Load Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ddaed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FILES_TO_LOAD = 30\n",
    "data_dir = Path(\"/home/gerk/sts_after_images/lichess_elite_np_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74efc49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_move = json.loads((data_dir / \"int_to_move.json\").read_text())\n",
    "int_to_move = {int(k): v for k, v in int_to_move.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3909ba23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from file number: 0\n",
      "There are now 7000 move examples\n",
      "loading from file number: 1\n",
      "There are now 14000 move examples\n",
      "loading from file number: 2\n",
      "There are now 21000 move examples\n",
      "loading from file number: 3\n",
      "There are now 28000 move examples\n",
      "loading from file number: 4\n",
      "There are now 35000 move examples\n",
      "loading from file number: 5\n",
      "There are now 42000 move examples\n",
      "loading from file number: 6\n",
      "There are now 49000 move examples\n",
      "loading from file number: 7\n",
      "There are now 56000 move examples\n",
      "loading from file number: 8\n",
      "There are now 63000 move examples\n",
      "loading from file number: 9\n",
      "There are now 70000 move examples\n",
      "loading from file number: 10\n",
      "There are now 77000 move examples\n",
      "loading from file number: 11\n",
      "There are now 84000 move examples\n",
      "loading from file number: 12\n",
      "There are now 91000 move examples\n",
      "loading from file number: 13\n",
      "There are now 98000 move examples\n",
      "loading from file number: 14\n",
      "There are now 105000 move examples\n",
      "loading from file number: 15\n",
      "There are now 112000 move examples\n",
      "loading from file number: 16\n",
      "There are now 119000 move examples\n",
      "loading from file number: 17\n",
      "There are now 126000 move examples\n",
      "loading from file number: 18\n",
      "There are now 133000 move examples\n",
      "loading from file number: 19\n",
      "There are now 140000 move examples\n",
      "loading from file number: 20\n",
      "There are now 147000 move examples\n",
      "loading from file number: 21\n",
      "There are now 154000 move examples\n",
      "loading from file number: 22\n",
      "There are now 161000 move examples\n",
      "loading from file number: 23\n",
      "There are now 168000 move examples\n",
      "loading from file number: 24\n",
      "There are now 175000 move examples\n",
      "loading from file number: 25\n",
      "There are now 182000 move examples\n",
      "loading from file number: 26\n",
      "There are now 189000 move examples\n",
      "loading from file number: 27\n",
      "There are now 196000 move examples\n",
      "loading from file number: 28\n",
      "There are now 203000 move examples\n",
      "loading from file number: 29\n",
      "There are now 210000 move examples\n"
     ]
    }
   ],
   "source": [
    "x, y = [], []\n",
    "n_moves = None\n",
    "\n",
    "i = 0\n",
    "while True:\n",
    "    if N_FILES_TO_LOAD is not None and i >= N_FILES_TO_LOAD:\n",
    "        break\n",
    "\n",
    "    x_file, y_file = Path(data_dir / f\"elite_db_x_{i}.npy\"), Path(data_dir / f\"elite_db_min_ohe_y_{i}.npy\")\n",
    "    if not x_file.exists() or not y_file.exists():\n",
    "        break\n",
    "    print(f\"loading from file number: {i}\")\n",
    "\n",
    "    x.extend(np.load(x_file))\n",
    "    y.extend(np.load(y_file))\n",
    "    n_moves = len(y[0])\n",
    "    i = i + 1\n",
    "    print(f\"There are now {len(x)} move examples\")\n",
    "\n",
    "x, y = np.array(x), np.array(y)\n",
    "y = np.argmax(y, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "712ee0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor = torch.from_numpy(x).float()  # Ensure correct data type (e.g., float32)\n",
    "y_tensor = torch.from_numpy(y).long()  # For labels, use long\n",
    "\n",
    "train_slice_idx = int((len(x) * 0.9))\n",
    "\n",
    "train_kwargs = {'batch_size': 64}\n",
    "test_kwargs = {'batch_size': 1000}\n",
    "cuda_kwargs = {'num_workers': 0,\n",
    "               'pin_memory': True,\n",
    "               'shuffle': True}\n",
    "train_kwargs.update(cuda_kwargs)\n",
    "test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "x_train, y_train = x_tensor[:train_slice_idx], y_tensor[:train_slice_idx]\n",
    "x_test, y_test = x_tensor[train_slice_idx:], y_tensor[train_slice_idx:]\n",
    "\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, **train_kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, **test_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a67bfe3",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6fdd215",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(8, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(512, 128)\n",
    "        self.fc2 = nn.Linear(128, len(all_uci_codes_to_moves()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1c8d2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed=42)\n",
    "device = torch.device(\"cuda\")\n",
    "model = Net().to(device)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=1.0)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3395ad6",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f405d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "patience = 10\n",
    "counter = 0\n",
    "best_model_state, best_loss_so_far = model.state_dict(), 9999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa0bcf4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/189000 (0%)]\tLoss: 7.593262\n",
      "Train Epoch: 1 [640/189000 (0%)]\tLoss: 7.575794\n",
      "Train Epoch: 1 [1280/189000 (1%)]\tLoss: 7.568964\n",
      "Train Epoch: 1 [1920/189000 (1%)]\tLoss: 7.468659\n",
      "Train Epoch: 1 [2560/189000 (1%)]\tLoss: 7.386392\n",
      "Train Epoch: 1 [3200/189000 (2%)]\tLoss: 7.210393\n",
      "Train Epoch: 1 [3840/189000 (2%)]\tLoss: 6.919970\n",
      "Train Epoch: 1 [4480/189000 (2%)]\tLoss: 6.632010\n",
      "Train Epoch: 1 [5120/189000 (3%)]\tLoss: 6.715740\n",
      "Train Epoch: 1 [5760/189000 (3%)]\tLoss: 6.938376\n",
      "Train Epoch: 1 [6400/189000 (3%)]\tLoss: 7.078294\n",
      "Train Epoch: 1 [7040/189000 (4%)]\tLoss: 6.767677\n",
      "Train Epoch: 1 [7680/189000 (4%)]\tLoss: 6.517745\n",
      "Train Epoch: 1 [8320/189000 (4%)]\tLoss: 7.017103\n",
      "Train Epoch: 1 [8960/189000 (5%)]\tLoss: 6.826654\n",
      "Train Epoch: 1 [9600/189000 (5%)]\tLoss: 7.058296\n",
      "Train Epoch: 1 [10240/189000 (5%)]\tLoss: 6.940141\n",
      "Train Epoch: 1 [10880/189000 (6%)]\tLoss: 6.859289\n",
      "Train Epoch: 1 [11520/189000 (6%)]\tLoss: 6.552064\n",
      "Train Epoch: 1 [12160/189000 (6%)]\tLoss: 6.573657\n",
      "Train Epoch: 1 [12800/189000 (7%)]\tLoss: 6.623814\n",
      "Train Epoch: 1 [13440/189000 (7%)]\tLoss: 6.822371\n",
      "Train Epoch: 1 [14080/189000 (7%)]\tLoss: 6.908905\n",
      "Train Epoch: 1 [14720/189000 (8%)]\tLoss: 6.736307\n",
      "Train Epoch: 1 [15360/189000 (8%)]\tLoss: 6.761481\n",
      "Train Epoch: 1 [16000/189000 (8%)]\tLoss: 6.676132\n",
      "Train Epoch: 1 [16640/189000 (9%)]\tLoss: 6.532231\n",
      "Train Epoch: 1 [17280/189000 (9%)]\tLoss: 6.975570\n",
      "Train Epoch: 1 [17920/189000 (9%)]\tLoss: 6.626987\n",
      "Train Epoch: 1 [18560/189000 (10%)]\tLoss: 6.528560\n",
      "Train Epoch: 1 [19200/189000 (10%)]\tLoss: 6.758830\n",
      "Train Epoch: 1 [19840/189000 (10%)]\tLoss: 6.725493\n",
      "Train Epoch: 1 [20480/189000 (11%)]\tLoss: 6.536654\n",
      "Train Epoch: 1 [21120/189000 (11%)]\tLoss: 6.764607\n",
      "Train Epoch: 1 [21760/189000 (12%)]\tLoss: 6.535555\n",
      "Train Epoch: 1 [22400/189000 (12%)]\tLoss: 6.444565\n",
      "Train Epoch: 1 [23040/189000 (12%)]\tLoss: 6.737591\n",
      "Train Epoch: 1 [23680/189000 (13%)]\tLoss: 6.312087\n",
      "Train Epoch: 1 [24320/189000 (13%)]\tLoss: 6.709370\n",
      "Train Epoch: 1 [24960/189000 (13%)]\tLoss: 6.710844\n",
      "Train Epoch: 1 [25600/189000 (14%)]\tLoss: 6.537199\n",
      "Train Epoch: 1 [26240/189000 (14%)]\tLoss: 6.371883\n",
      "Train Epoch: 1 [26880/189000 (14%)]\tLoss: 6.641167\n",
      "Train Epoch: 1 [27520/189000 (15%)]\tLoss: 6.596628\n",
      "Train Epoch: 1 [28160/189000 (15%)]\tLoss: 6.576829\n",
      "Train Epoch: 1 [28800/189000 (15%)]\tLoss: 6.696977\n",
      "Train Epoch: 1 [29440/189000 (16%)]\tLoss: 6.698224\n",
      "Train Epoch: 1 [30080/189000 (16%)]\tLoss: 6.572227\n",
      "Train Epoch: 1 [30720/189000 (16%)]\tLoss: 6.994618\n",
      "Train Epoch: 1 [31360/189000 (17%)]\tLoss: 7.026336\n",
      "Train Epoch: 1 [32000/189000 (17%)]\tLoss: 6.550450\n",
      "Train Epoch: 1 [32640/189000 (17%)]\tLoss: 6.546552\n",
      "Train Epoch: 1 [33280/189000 (18%)]\tLoss: 6.702429\n",
      "Train Epoch: 1 [33920/189000 (18%)]\tLoss: 6.593998\n",
      "Train Epoch: 1 [34560/189000 (18%)]\tLoss: 6.571341\n",
      "Train Epoch: 1 [35200/189000 (19%)]\tLoss: 6.818489\n",
      "Train Epoch: 1 [35840/189000 (19%)]\tLoss: 6.445531\n",
      "Train Epoch: 1 [36480/189000 (19%)]\tLoss: 6.719098\n",
      "Train Epoch: 1 [37120/189000 (20%)]\tLoss: 6.581166\n",
      "Train Epoch: 1 [37760/189000 (20%)]\tLoss: 6.777643\n",
      "Train Epoch: 1 [38400/189000 (20%)]\tLoss: 6.854967\n",
      "Train Epoch: 1 [39040/189000 (21%)]\tLoss: 6.554859\n",
      "Train Epoch: 1 [39680/189000 (21%)]\tLoss: 6.745441\n",
      "Train Epoch: 1 [40320/189000 (21%)]\tLoss: 6.780674\n",
      "Train Epoch: 1 [40960/189000 (22%)]\tLoss: 6.557336\n",
      "Train Epoch: 1 [41600/189000 (22%)]\tLoss: 6.862783\n",
      "Train Epoch: 1 [42240/189000 (22%)]\tLoss: 6.418063\n",
      "Train Epoch: 1 [42880/189000 (23%)]\tLoss: 6.620302\n",
      "Train Epoch: 1 [43520/189000 (23%)]\tLoss: 6.513028\n",
      "Train Epoch: 1 [44160/189000 (23%)]\tLoss: 6.673373\n",
      "Train Epoch: 1 [44800/189000 (24%)]\tLoss: 6.636939\n",
      "Train Epoch: 1 [45440/189000 (24%)]\tLoss: 6.765555\n",
      "Train Epoch: 1 [46080/189000 (24%)]\tLoss: 6.663371\n",
      "Train Epoch: 1 [46720/189000 (25%)]\tLoss: 6.495967\n",
      "Train Epoch: 1 [47360/189000 (25%)]\tLoss: 6.724687\n",
      "Train Epoch: 1 [48000/189000 (25%)]\tLoss: 6.414330\n",
      "Train Epoch: 1 [48640/189000 (26%)]\tLoss: 6.924053\n",
      "Train Epoch: 1 [49280/189000 (26%)]\tLoss: 6.534688\n",
      "Train Epoch: 1 [49920/189000 (26%)]\tLoss: 6.736801\n",
      "Train Epoch: 1 [50560/189000 (27%)]\tLoss: 6.883636\n",
      "Train Epoch: 1 [51200/189000 (27%)]\tLoss: 6.659622\n",
      "Train Epoch: 1 [51840/189000 (27%)]\tLoss: 6.741616\n",
      "Train Epoch: 1 [52480/189000 (28%)]\tLoss: 6.300840\n",
      "Train Epoch: 1 [53120/189000 (28%)]\tLoss: 6.412141\n",
      "Train Epoch: 1 [53760/189000 (28%)]\tLoss: 6.707328\n",
      "Train Epoch: 1 [54400/189000 (29%)]\tLoss: 6.588767\n",
      "Train Epoch: 1 [55040/189000 (29%)]\tLoss: 6.494288\n",
      "Train Epoch: 1 [55680/189000 (29%)]\tLoss: 6.495762\n",
      "Train Epoch: 1 [56320/189000 (30%)]\tLoss: 6.509416\n",
      "Train Epoch: 1 [56960/189000 (30%)]\tLoss: 6.824319\n",
      "Train Epoch: 1 [57600/189000 (30%)]\tLoss: 6.436219\n",
      "Train Epoch: 1 [58240/189000 (31%)]\tLoss: 6.327329\n",
      "Train Epoch: 1 [58880/189000 (31%)]\tLoss: 6.600268\n",
      "Train Epoch: 1 [59520/189000 (31%)]\tLoss: 6.917878\n",
      "Train Epoch: 1 [60160/189000 (32%)]\tLoss: 6.637199\n",
      "Train Epoch: 1 [60800/189000 (32%)]\tLoss: 6.632928\n",
      "Train Epoch: 1 [61440/189000 (32%)]\tLoss: 6.728695\n",
      "Train Epoch: 1 [62080/189000 (33%)]\tLoss: 6.525310\n",
      "Train Epoch: 1 [62720/189000 (33%)]\tLoss: 6.550178\n",
      "Train Epoch: 1 [63360/189000 (34%)]\tLoss: 6.644811\n",
      "Train Epoch: 1 [64000/189000 (34%)]\tLoss: 6.707763\n",
      "Train Epoch: 1 [64640/189000 (34%)]\tLoss: 6.823627\n",
      "Train Epoch: 1 [65280/189000 (35%)]\tLoss: 6.806329\n",
      "Train Epoch: 1 [65920/189000 (35%)]\tLoss: 6.508490\n",
      "Train Epoch: 1 [66560/189000 (35%)]\tLoss: 6.716447\n",
      "Train Epoch: 1 [67200/189000 (36%)]\tLoss: 6.573233\n",
      "Train Epoch: 1 [67840/189000 (36%)]\tLoss: 6.813835\n",
      "Train Epoch: 1 [68480/189000 (36%)]\tLoss: 6.714861\n",
      "Train Epoch: 1 [69120/189000 (37%)]\tLoss: 6.561727\n",
      "Train Epoch: 1 [69760/189000 (37%)]\tLoss: 6.333633\n",
      "Train Epoch: 1 [70400/189000 (37%)]\tLoss: 6.766401\n",
      "Train Epoch: 1 [71040/189000 (38%)]\tLoss: 6.681554\n",
      "Train Epoch: 1 [71680/189000 (38%)]\tLoss: 6.672511\n",
      "Train Epoch: 1 [72320/189000 (38%)]\tLoss: 6.461711\n",
      "Train Epoch: 1 [72960/189000 (39%)]\tLoss: 6.805102\n",
      "Train Epoch: 1 [73600/189000 (39%)]\tLoss: 6.542169\n",
      "Train Epoch: 1 [74240/189000 (39%)]\tLoss: 6.209842\n",
      "Train Epoch: 1 [74880/189000 (40%)]\tLoss: 6.597303\n",
      "Train Epoch: 1 [75520/189000 (40%)]\tLoss: 6.430475\n",
      "Train Epoch: 1 [76160/189000 (40%)]\tLoss: 6.696400\n",
      "Train Epoch: 1 [76800/189000 (41%)]\tLoss: 6.407493\n",
      "Train Epoch: 1 [77440/189000 (41%)]\tLoss: 6.558385\n",
      "Train Epoch: 1 [78080/189000 (41%)]\tLoss: 6.331770\n",
      "Train Epoch: 1 [78720/189000 (42%)]\tLoss: 6.813605\n",
      "Train Epoch: 1 [79360/189000 (42%)]\tLoss: 6.441634\n",
      "Train Epoch: 1 [80000/189000 (42%)]\tLoss: 6.469913\n",
      "Train Epoch: 1 [80640/189000 (43%)]\tLoss: 6.815976\n",
      "Train Epoch: 1 [81280/189000 (43%)]\tLoss: 6.502966\n",
      "Train Epoch: 1 [81920/189000 (43%)]\tLoss: 6.736347\n",
      "Train Epoch: 1 [82560/189000 (44%)]\tLoss: 6.465672\n",
      "Train Epoch: 1 [83200/189000 (44%)]\tLoss: 6.257685\n",
      "Train Epoch: 1 [83840/189000 (44%)]\tLoss: 6.413998\n",
      "Train Epoch: 1 [84480/189000 (45%)]\tLoss: 6.605924\n",
      "Train Epoch: 1 [85120/189000 (45%)]\tLoss: 5.825327\n",
      "Train Epoch: 1 [85760/189000 (45%)]\tLoss: 6.513282\n",
      "Train Epoch: 1 [86400/189000 (46%)]\tLoss: 6.928692\n",
      "Train Epoch: 1 [87040/189000 (46%)]\tLoss: 6.663646\n",
      "Train Epoch: 1 [87680/189000 (46%)]\tLoss: 6.494634\n",
      "Train Epoch: 1 [88320/189000 (47%)]\tLoss: 6.804180\n",
      "Train Epoch: 1 [88960/189000 (47%)]\tLoss: 6.843815\n",
      "Train Epoch: 1 [89600/189000 (47%)]\tLoss: 6.724143\n",
      "Train Epoch: 1 [90240/189000 (48%)]\tLoss: 6.828222\n",
      "Train Epoch: 1 [90880/189000 (48%)]\tLoss: 6.468708\n",
      "Train Epoch: 1 [91520/189000 (48%)]\tLoss: 7.009011\n",
      "Train Epoch: 1 [92160/189000 (49%)]\tLoss: 6.727370\n",
      "Train Epoch: 1 [92800/189000 (49%)]\tLoss: 6.316160\n",
      "Train Epoch: 1 [93440/189000 (49%)]\tLoss: 6.650370\n",
      "Train Epoch: 1 [94080/189000 (50%)]\tLoss: 6.714728\n",
      "Train Epoch: 1 [94720/189000 (50%)]\tLoss: 6.473953\n",
      "Train Epoch: 1 [95360/189000 (50%)]\tLoss: 6.792583\n",
      "Train Epoch: 1 [96000/189000 (51%)]\tLoss: 6.718327\n",
      "Train Epoch: 1 [96640/189000 (51%)]\tLoss: 6.276839\n",
      "Train Epoch: 1 [97280/189000 (51%)]\tLoss: 6.644791\n",
      "Train Epoch: 1 [97920/189000 (52%)]\tLoss: 6.562646\n",
      "Train Epoch: 1 [98560/189000 (52%)]\tLoss: 6.076018\n",
      "Train Epoch: 1 [99200/189000 (52%)]\tLoss: 6.553654\n",
      "Train Epoch: 1 [99840/189000 (53%)]\tLoss: 6.691990\n",
      "Train Epoch: 1 [100480/189000 (53%)]\tLoss: 6.641673\n",
      "Train Epoch: 1 [101120/189000 (53%)]\tLoss: 6.919243\n",
      "Train Epoch: 1 [101760/189000 (54%)]\tLoss: 6.576397\n",
      "Train Epoch: 1 [102400/189000 (54%)]\tLoss: 6.423432\n",
      "Train Epoch: 1 [103040/189000 (55%)]\tLoss: 6.368526\n",
      "Train Epoch: 1 [103680/189000 (55%)]\tLoss: 6.528647\n",
      "Train Epoch: 1 [104320/189000 (55%)]\tLoss: 6.787326\n",
      "Train Epoch: 1 [104960/189000 (56%)]\tLoss: 6.664286\n",
      "Train Epoch: 1 [105600/189000 (56%)]\tLoss: 6.502938\n",
      "Train Epoch: 1 [106240/189000 (56%)]\tLoss: 6.437289\n",
      "Train Epoch: 1 [106880/189000 (57%)]\tLoss: 6.933117\n",
      "Train Epoch: 1 [107520/189000 (57%)]\tLoss: 6.346759\n",
      "Train Epoch: 1 [108160/189000 (57%)]\tLoss: 6.617955\n",
      "Train Epoch: 1 [108800/189000 (58%)]\tLoss: 6.266281\n",
      "Train Epoch: 1 [109440/189000 (58%)]\tLoss: 6.153441\n",
      "Train Epoch: 1 [110080/189000 (58%)]\tLoss: 6.673534\n",
      "Train Epoch: 1 [110720/189000 (59%)]\tLoss: 6.219829\n",
      "Train Epoch: 1 [111360/189000 (59%)]\tLoss: 6.325596\n",
      "Train Epoch: 1 [112000/189000 (59%)]\tLoss: 6.400469\n",
      "Train Epoch: 1 [112640/189000 (60%)]\tLoss: 6.776848\n",
      "Train Epoch: 1 [113280/189000 (60%)]\tLoss: 6.632270\n",
      "Train Epoch: 1 [113920/189000 (60%)]\tLoss: 6.768069\n",
      "Train Epoch: 1 [114560/189000 (61%)]\tLoss: 6.661233\n",
      "Train Epoch: 1 [115200/189000 (61%)]\tLoss: 6.772084\n",
      "Train Epoch: 1 [115840/189000 (61%)]\tLoss: 6.548502\n",
      "Train Epoch: 1 [116480/189000 (62%)]\tLoss: 6.402503\n",
      "Train Epoch: 1 [117120/189000 (62%)]\tLoss: 6.518387\n",
      "Train Epoch: 1 [117760/189000 (62%)]\tLoss: 6.583007\n",
      "Train Epoch: 1 [118400/189000 (63%)]\tLoss: 6.253636\n",
      "Train Epoch: 1 [119040/189000 (63%)]\tLoss: 6.526515\n",
      "Train Epoch: 1 [119680/189000 (63%)]\tLoss: 6.956905\n",
      "Train Epoch: 1 [120320/189000 (64%)]\tLoss: 6.736324\n",
      "Train Epoch: 1 [120960/189000 (64%)]\tLoss: 6.783407\n",
      "Train Epoch: 1 [121600/189000 (64%)]\tLoss: 6.622278\n",
      "Train Epoch: 1 [122240/189000 (65%)]\tLoss: 6.427466\n",
      "Train Epoch: 1 [122880/189000 (65%)]\tLoss: 6.824476\n",
      "Train Epoch: 1 [123520/189000 (65%)]\tLoss: 6.220638\n",
      "Train Epoch: 1 [124160/189000 (66%)]\tLoss: 6.154268\n",
      "Train Epoch: 1 [124800/189000 (66%)]\tLoss: 6.745962\n",
      "Train Epoch: 1 [125440/189000 (66%)]\tLoss: 6.738871\n",
      "Train Epoch: 1 [126080/189000 (67%)]\tLoss: 6.705835\n",
      "Train Epoch: 1 [126720/189000 (67%)]\tLoss: 6.526503\n",
      "Train Epoch: 1 [127360/189000 (67%)]\tLoss: 6.105211\n",
      "Train Epoch: 1 [128000/189000 (68%)]\tLoss: 6.583852\n",
      "Train Epoch: 1 [128640/189000 (68%)]\tLoss: 6.624487\n",
      "Train Epoch: 1 [129280/189000 (68%)]\tLoss: 6.446382\n",
      "Train Epoch: 1 [129920/189000 (69%)]\tLoss: 6.866799\n",
      "Train Epoch: 1 [130560/189000 (69%)]\tLoss: 6.546095\n",
      "Train Epoch: 1 [131200/189000 (69%)]\tLoss: 6.654225\n",
      "Train Epoch: 1 [131840/189000 (70%)]\tLoss: 6.458679\n",
      "Train Epoch: 1 [132480/189000 (70%)]\tLoss: 6.804166\n",
      "Train Epoch: 1 [133120/189000 (70%)]\tLoss: 6.374130\n",
      "Train Epoch: 1 [133760/189000 (71%)]\tLoss: 6.565450\n",
      "Train Epoch: 1 [134400/189000 (71%)]\tLoss: 6.440443\n",
      "Train Epoch: 1 [135040/189000 (71%)]\tLoss: 6.766781\n",
      "Train Epoch: 1 [135680/189000 (72%)]\tLoss: 6.448924\n",
      "Train Epoch: 1 [136320/189000 (72%)]\tLoss: 6.238067\n",
      "Train Epoch: 1 [136960/189000 (72%)]\tLoss: 6.324433\n",
      "Train Epoch: 1 [137600/189000 (73%)]\tLoss: 6.739162\n",
      "Train Epoch: 1 [138240/189000 (73%)]\tLoss: 6.651393\n",
      "Train Epoch: 1 [138880/189000 (73%)]\tLoss: 6.632762\n",
      "Train Epoch: 1 [139520/189000 (74%)]\tLoss: 6.672047\n",
      "Train Epoch: 1 [140160/189000 (74%)]\tLoss: 6.538455\n",
      "Train Epoch: 1 [140800/189000 (74%)]\tLoss: 6.858211\n",
      "Train Epoch: 1 [141440/189000 (75%)]\tLoss: 6.345340\n",
      "Train Epoch: 1 [142080/189000 (75%)]\tLoss: 6.650316\n",
      "Train Epoch: 1 [142720/189000 (75%)]\tLoss: 6.736837\n",
      "Train Epoch: 1 [143360/189000 (76%)]\tLoss: 6.367681\n",
      "Train Epoch: 1 [144000/189000 (76%)]\tLoss: 6.277398\n",
      "Train Epoch: 1 [144640/189000 (77%)]\tLoss: 6.586152\n",
      "Train Epoch: 1 [145280/189000 (77%)]\tLoss: 6.288010\n",
      "Train Epoch: 1 [145920/189000 (77%)]\tLoss: 6.315198\n",
      "Train Epoch: 1 [146560/189000 (78%)]\tLoss: 6.252988\n",
      "Train Epoch: 1 [147200/189000 (78%)]\tLoss: 6.276443\n",
      "Train Epoch: 1 [147840/189000 (78%)]\tLoss: 6.968211\n",
      "Train Epoch: 1 [148480/189000 (79%)]\tLoss: 6.624545\n",
      "Train Epoch: 1 [149120/189000 (79%)]\tLoss: 6.480892\n",
      "Train Epoch: 1 [149760/189000 (79%)]\tLoss: 6.421230\n",
      "Train Epoch: 1 [150400/189000 (80%)]\tLoss: 6.538805\n",
      "Train Epoch: 1 [151040/189000 (80%)]\tLoss: 6.579152\n",
      "Train Epoch: 1 [151680/189000 (80%)]\tLoss: 6.030241\n",
      "Train Epoch: 1 [152320/189000 (81%)]\tLoss: 6.518272\n",
      "Train Epoch: 1 [152960/189000 (81%)]\tLoss: 6.340122\n",
      "Train Epoch: 1 [153600/189000 (81%)]\tLoss: 6.386717\n",
      "Train Epoch: 1 [154240/189000 (82%)]\tLoss: 6.692211\n",
      "Train Epoch: 1 [154880/189000 (82%)]\tLoss: 6.646826\n",
      "Train Epoch: 1 [155520/189000 (82%)]\tLoss: 6.689242\n",
      "Train Epoch: 1 [156160/189000 (83%)]\tLoss: 6.825323\n",
      "Train Epoch: 1 [156800/189000 (83%)]\tLoss: 6.746158\n",
      "Train Epoch: 1 [157440/189000 (83%)]\tLoss: 6.531736\n",
      "Train Epoch: 1 [158080/189000 (84%)]\tLoss: 6.189167\n",
      "Train Epoch: 1 [158720/189000 (84%)]\tLoss: 6.414903\n",
      "Train Epoch: 1 [159360/189000 (84%)]\tLoss: 6.360115\n",
      "Train Epoch: 1 [160000/189000 (85%)]\tLoss: 6.500271\n",
      "Train Epoch: 1 [160640/189000 (85%)]\tLoss: 6.078703\n",
      "Train Epoch: 1 [161280/189000 (85%)]\tLoss: 6.433887\n",
      "Train Epoch: 1 [161920/189000 (86%)]\tLoss: 6.225079\n",
      "Train Epoch: 1 [162560/189000 (86%)]\tLoss: 6.842442\n",
      "Train Epoch: 1 [163200/189000 (86%)]\tLoss: 6.523695\n",
      "Train Epoch: 1 [163840/189000 (87%)]\tLoss: 6.837780\n",
      "Train Epoch: 1 [164480/189000 (87%)]\tLoss: 6.586663\n",
      "Train Epoch: 1 [165120/189000 (87%)]\tLoss: 6.597479\n",
      "Train Epoch: 1 [165760/189000 (88%)]\tLoss: 6.630086\n",
      "Train Epoch: 1 [166400/189000 (88%)]\tLoss: 6.877637\n",
      "Train Epoch: 1 [167040/189000 (88%)]\tLoss: 6.411310\n",
      "Train Epoch: 1 [167680/189000 (89%)]\tLoss: 6.775429\n",
      "Train Epoch: 1 [168320/189000 (89%)]\tLoss: 6.185363\n",
      "Train Epoch: 1 [168960/189000 (89%)]\tLoss: 6.576775\n",
      "Train Epoch: 1 [169600/189000 (90%)]\tLoss: 6.702019\n",
      "Train Epoch: 1 [170240/189000 (90%)]\tLoss: 6.774972\n",
      "Train Epoch: 1 [170880/189000 (90%)]\tLoss: 6.318014\n",
      "Train Epoch: 1 [171520/189000 (91%)]\tLoss: 6.323248\n",
      "Train Epoch: 1 [172160/189000 (91%)]\tLoss: 6.343351\n",
      "Train Epoch: 1 [172800/189000 (91%)]\tLoss: 6.516901\n",
      "Train Epoch: 1 [173440/189000 (92%)]\tLoss: 6.726015\n",
      "Train Epoch: 1 [174080/189000 (92%)]\tLoss: 6.679187\n",
      "Train Epoch: 1 [174720/189000 (92%)]\tLoss: 6.474924\n",
      "Train Epoch: 1 [175360/189000 (93%)]\tLoss: 6.572557\n",
      "Train Epoch: 1 [176000/189000 (93%)]\tLoss: 6.250536\n",
      "Train Epoch: 1 [176640/189000 (93%)]\tLoss: 6.746147\n",
      "Train Epoch: 1 [177280/189000 (94%)]\tLoss: 6.348737\n",
      "Train Epoch: 1 [177920/189000 (94%)]\tLoss: 6.478005\n",
      "Train Epoch: 1 [178560/189000 (94%)]\tLoss: 6.912051\n",
      "Train Epoch: 1 [179200/189000 (95%)]\tLoss: 6.705321\n",
      "Train Epoch: 1 [179840/189000 (95%)]\tLoss: 6.238429\n",
      "Train Epoch: 1 [180480/189000 (95%)]\tLoss: 6.526354\n",
      "Train Epoch: 1 [181120/189000 (96%)]\tLoss: 6.158942\n",
      "Train Epoch: 1 [181760/189000 (96%)]\tLoss: 6.214337\n",
      "Train Epoch: 1 [182400/189000 (96%)]\tLoss: 6.712779\n",
      "Train Epoch: 1 [183040/189000 (97%)]\tLoss: 6.461510\n",
      "Train Epoch: 1 [183680/189000 (97%)]\tLoss: 6.459705\n",
      "Train Epoch: 1 [184320/189000 (97%)]\tLoss: 6.445693\n",
      "Train Epoch: 1 [184960/189000 (98%)]\tLoss: 6.646873\n",
      "Train Epoch: 1 [185600/189000 (98%)]\tLoss: 6.801263\n",
      "Train Epoch: 1 [186240/189000 (99%)]\tLoss: 6.621292\n",
      "Train Epoch: 1 [186880/189000 (99%)]\tLoss: 6.617020\n",
      "Train Epoch: 1 [187520/189000 (99%)]\tLoss: 7.017800\n",
      "Train Epoch: 1 [188160/189000 (100%)]\tLoss: 6.464884\n",
      "Train Epoch: 1 [188800/189000 (100%)]\tLoss: 6.743731\n",
      "\n",
      "Test set: Average loss: 6.4460, Accuracy: 887/21000 (4%)\n",
      "\n",
      "Train Epoch: 2 [0/189000 (0%)]\tLoss: 6.794676\n",
      "Train Epoch: 2 [640/189000 (0%)]\tLoss: 6.366134\n",
      "Train Epoch: 2 [1280/189000 (1%)]\tLoss: 6.388083\n",
      "Train Epoch: 2 [1920/189000 (1%)]\tLoss: 6.244685\n",
      "Train Epoch: 2 [2560/189000 (1%)]\tLoss: 6.747394\n",
      "Train Epoch: 2 [3200/189000 (2%)]\tLoss: 6.196103\n",
      "Train Epoch: 2 [3840/189000 (2%)]\tLoss: 6.462299\n",
      "Train Epoch: 2 [4480/189000 (2%)]\tLoss: 6.447795\n",
      "Train Epoch: 2 [5120/189000 (3%)]\tLoss: 6.420418\n",
      "Train Epoch: 2 [5760/189000 (3%)]\tLoss: 6.637661\n",
      "Train Epoch: 2 [6400/189000 (3%)]\tLoss: 6.653800\n",
      "Train Epoch: 2 [7040/189000 (4%)]\tLoss: 6.305478\n",
      "Train Epoch: 2 [7680/189000 (4%)]\tLoss: 6.492749\n",
      "Train Epoch: 2 [8320/189000 (4%)]\tLoss: 6.440298\n",
      "Train Epoch: 2 [8960/189000 (5%)]\tLoss: 6.534049\n",
      "Train Epoch: 2 [9600/189000 (5%)]\tLoss: 6.357240\n",
      "Train Epoch: 2 [10240/189000 (5%)]\tLoss: 6.505821\n",
      "Train Epoch: 2 [10880/189000 (6%)]\tLoss: 6.704228\n",
      "Train Epoch: 2 [11520/189000 (6%)]\tLoss: 6.865383\n",
      "Train Epoch: 2 [12160/189000 (6%)]\tLoss: 6.571100\n",
      "Train Epoch: 2 [12800/189000 (7%)]\tLoss: 6.753595\n",
      "Train Epoch: 2 [13440/189000 (7%)]\tLoss: 6.275942\n",
      "Train Epoch: 2 [14080/189000 (7%)]\tLoss: 6.208965\n",
      "Train Epoch: 2 [14720/189000 (8%)]\tLoss: 6.360018\n",
      "Train Epoch: 2 [15360/189000 (8%)]\tLoss: 6.493202\n",
      "Train Epoch: 2 [16000/189000 (8%)]\tLoss: 6.741569\n",
      "Train Epoch: 2 [16640/189000 (9%)]\tLoss: 6.251832\n",
      "Train Epoch: 2 [17280/189000 (9%)]\tLoss: 6.246093\n",
      "Train Epoch: 2 [17920/189000 (9%)]\tLoss: 6.507195\n",
      "Train Epoch: 2 [18560/189000 (10%)]\tLoss: 6.152555\n",
      "Train Epoch: 2 [19200/189000 (10%)]\tLoss: 6.360536\n",
      "Train Epoch: 2 [19840/189000 (10%)]\tLoss: 6.094679\n",
      "Train Epoch: 2 [20480/189000 (11%)]\tLoss: 6.385469\n",
      "Train Epoch: 2 [21120/189000 (11%)]\tLoss: 6.841205\n",
      "Train Epoch: 2 [21760/189000 (12%)]\tLoss: 6.253280\n",
      "Train Epoch: 2 [22400/189000 (12%)]\tLoss: 6.526597\n",
      "Train Epoch: 2 [23040/189000 (12%)]\tLoss: 6.621421\n",
      "Train Epoch: 2 [23680/189000 (13%)]\tLoss: 6.645106\n",
      "Train Epoch: 2 [24320/189000 (13%)]\tLoss: 6.809722\n",
      "Train Epoch: 2 [24960/189000 (13%)]\tLoss: 6.647927\n",
      "Train Epoch: 2 [25600/189000 (14%)]\tLoss: 6.902211\n",
      "Train Epoch: 2 [26240/189000 (14%)]\tLoss: 6.227288\n",
      "Train Epoch: 2 [26880/189000 (14%)]\tLoss: 6.306611\n",
      "Train Epoch: 2 [27520/189000 (15%)]\tLoss: 6.422866\n",
      "Train Epoch: 2 [28160/189000 (15%)]\tLoss: 6.285860\n",
      "Train Epoch: 2 [28800/189000 (15%)]\tLoss: 6.419202\n",
      "Train Epoch: 2 [29440/189000 (16%)]\tLoss: 6.473719\n",
      "Train Epoch: 2 [30080/189000 (16%)]\tLoss: 6.395175\n",
      "Train Epoch: 2 [30720/189000 (16%)]\tLoss: 6.770854\n",
      "Train Epoch: 2 [31360/189000 (17%)]\tLoss: 6.562465\n",
      "Train Epoch: 2 [32000/189000 (17%)]\tLoss: 6.406949\n",
      "Train Epoch: 2 [32640/189000 (17%)]\tLoss: 6.567585\n",
      "Train Epoch: 2 [33280/189000 (18%)]\tLoss: 6.312582\n",
      "Train Epoch: 2 [33920/189000 (18%)]\tLoss: 6.795451\n",
      "Train Epoch: 2 [34560/189000 (18%)]\tLoss: 6.647869\n",
      "Train Epoch: 2 [35200/189000 (19%)]\tLoss: 6.112928\n",
      "Train Epoch: 2 [35840/189000 (19%)]\tLoss: 6.019200\n",
      "Train Epoch: 2 [36480/189000 (19%)]\tLoss: 6.234035\n",
      "Train Epoch: 2 [37120/189000 (20%)]\tLoss: 6.428517\n",
      "Train Epoch: 2 [37760/189000 (20%)]\tLoss: 6.700947\n",
      "Train Epoch: 2 [38400/189000 (20%)]\tLoss: 6.704618\n",
      "Train Epoch: 2 [39040/189000 (21%)]\tLoss: 6.577518\n",
      "Train Epoch: 2 [39680/189000 (21%)]\tLoss: 6.139562\n",
      "Train Epoch: 2 [40320/189000 (21%)]\tLoss: 6.485753\n",
      "Train Epoch: 2 [40960/189000 (22%)]\tLoss: 6.680529\n",
      "Train Epoch: 2 [41600/189000 (22%)]\tLoss: 6.353074\n",
      "Train Epoch: 2 [42240/189000 (22%)]\tLoss: 6.436046\n",
      "Train Epoch: 2 [42880/189000 (23%)]\tLoss: 6.517569\n",
      "Train Epoch: 2 [43520/189000 (23%)]\tLoss: 6.507085\n",
      "Train Epoch: 2 [44160/189000 (23%)]\tLoss: 6.403644\n",
      "Train Epoch: 2 [44800/189000 (24%)]\tLoss: 6.498966\n",
      "Train Epoch: 2 [45440/189000 (24%)]\tLoss: 6.414667\n",
      "Train Epoch: 2 [46080/189000 (24%)]\tLoss: 6.362809\n",
      "Train Epoch: 2 [46720/189000 (25%)]\tLoss: 6.836597\n",
      "Train Epoch: 2 [47360/189000 (25%)]\tLoss: 6.404215\n",
      "Train Epoch: 2 [48000/189000 (25%)]\tLoss: 6.397081\n",
      "Train Epoch: 2 [48640/189000 (26%)]\tLoss: 6.779535\n",
      "Train Epoch: 2 [49280/189000 (26%)]\tLoss: 6.156322\n",
      "Train Epoch: 2 [49920/189000 (26%)]\tLoss: 6.591145\n",
      "Train Epoch: 2 [50560/189000 (27%)]\tLoss: 6.634968\n",
      "Train Epoch: 2 [51200/189000 (27%)]\tLoss: 6.617763\n",
      "Train Epoch: 2 [51840/189000 (27%)]\tLoss: 6.378311\n",
      "Train Epoch: 2 [52480/189000 (28%)]\tLoss: 6.482371\n",
      "Train Epoch: 2 [53120/189000 (28%)]\tLoss: 6.543318\n",
      "Train Epoch: 2 [53760/189000 (28%)]\tLoss: 6.921401\n",
      "Train Epoch: 2 [54400/189000 (29%)]\tLoss: 6.638052\n",
      "Train Epoch: 2 [55040/189000 (29%)]\tLoss: 6.582648\n",
      "Train Epoch: 2 [55680/189000 (29%)]\tLoss: 6.602947\n",
      "Train Epoch: 2 [56320/189000 (30%)]\tLoss: 6.873387\n",
      "Train Epoch: 2 [56960/189000 (30%)]\tLoss: 6.206985\n",
      "Train Epoch: 2 [57600/189000 (30%)]\tLoss: 6.263121\n",
      "Train Epoch: 2 [58240/189000 (31%)]\tLoss: 6.504955\n",
      "Train Epoch: 2 [58880/189000 (31%)]\tLoss: 6.683604\n",
      "Train Epoch: 2 [59520/189000 (31%)]\tLoss: 6.704133\n",
      "Train Epoch: 2 [60160/189000 (32%)]\tLoss: 6.577942\n",
      "Train Epoch: 2 [60800/189000 (32%)]\tLoss: 6.475992\n",
      "Train Epoch: 2 [61440/189000 (32%)]\tLoss: 6.507746\n",
      "Train Epoch: 2 [62080/189000 (33%)]\tLoss: 6.719215\n",
      "Train Epoch: 2 [62720/189000 (33%)]\tLoss: 6.547509\n",
      "Train Epoch: 2 [63360/189000 (34%)]\tLoss: 6.248126\n",
      "Train Epoch: 2 [64000/189000 (34%)]\tLoss: 6.508974\n",
      "Train Epoch: 2 [64640/189000 (34%)]\tLoss: 6.369695\n",
      "Train Epoch: 2 [65280/189000 (35%)]\tLoss: 6.607850\n",
      "Train Epoch: 2 [65920/189000 (35%)]\tLoss: 6.537246\n",
      "Train Epoch: 2 [66560/189000 (35%)]\tLoss: 6.759014\n",
      "Train Epoch: 2 [67200/189000 (36%)]\tLoss: 6.289156\n",
      "Train Epoch: 2 [67840/189000 (36%)]\tLoss: 6.421413\n",
      "Train Epoch: 2 [68480/189000 (36%)]\tLoss: 6.902380\n",
      "Train Epoch: 2 [69120/189000 (37%)]\tLoss: 6.478242\n",
      "Train Epoch: 2 [69760/189000 (37%)]\tLoss: 7.056877\n",
      "Train Epoch: 2 [70400/189000 (37%)]\tLoss: 6.262009\n",
      "Train Epoch: 2 [71040/189000 (38%)]\tLoss: 6.767877\n",
      "Train Epoch: 2 [71680/189000 (38%)]\tLoss: 6.882527\n",
      "Train Epoch: 2 [72320/189000 (38%)]\tLoss: 6.203855\n",
      "Train Epoch: 2 [72960/189000 (39%)]\tLoss: 6.497733\n",
      "Train Epoch: 2 [73600/189000 (39%)]\tLoss: 6.952572\n",
      "Train Epoch: 2 [74240/189000 (39%)]\tLoss: 6.726232\n",
      "Train Epoch: 2 [74880/189000 (40%)]\tLoss: 6.238050\n",
      "Train Epoch: 2 [75520/189000 (40%)]\tLoss: 6.403433\n",
      "Train Epoch: 2 [76160/189000 (40%)]\tLoss: 6.205987\n",
      "Train Epoch: 2 [76800/189000 (41%)]\tLoss: 6.923776\n",
      "Train Epoch: 2 [77440/189000 (41%)]\tLoss: 6.216615\n",
      "Train Epoch: 2 [78080/189000 (41%)]\tLoss: 6.673852\n",
      "Train Epoch: 2 [78720/189000 (42%)]\tLoss: 6.656163\n",
      "Train Epoch: 2 [79360/189000 (42%)]\tLoss: 6.718035\n",
      "Train Epoch: 2 [80000/189000 (42%)]\tLoss: 6.405655\n",
      "Train Epoch: 2 [80640/189000 (43%)]\tLoss: 6.330080\n",
      "Train Epoch: 2 [81280/189000 (43%)]\tLoss: 6.575459\n",
      "Train Epoch: 2 [81920/189000 (43%)]\tLoss: 6.414074\n",
      "Train Epoch: 2 [82560/189000 (44%)]\tLoss: 6.510662\n",
      "Train Epoch: 2 [83200/189000 (44%)]\tLoss: 6.559622\n",
      "Train Epoch: 2 [83840/189000 (44%)]\tLoss: 6.742833\n",
      "Train Epoch: 2 [84480/189000 (45%)]\tLoss: 6.594644\n",
      "Train Epoch: 2 [85120/189000 (45%)]\tLoss: 6.519214\n",
      "Train Epoch: 2 [85760/189000 (45%)]\tLoss: 6.486577\n",
      "Train Epoch: 2 [86400/189000 (46%)]\tLoss: 6.885719\n",
      "Train Epoch: 2 [87040/189000 (46%)]\tLoss: 6.519857\n",
      "Train Epoch: 2 [87680/189000 (46%)]\tLoss: 6.616756\n",
      "Train Epoch: 2 [88320/189000 (47%)]\tLoss: 6.993280\n",
      "Train Epoch: 2 [88960/189000 (47%)]\tLoss: 6.639615\n",
      "Train Epoch: 2 [89600/189000 (47%)]\tLoss: 6.290158\n",
      "Train Epoch: 2 [90240/189000 (48%)]\tLoss: 6.853376\n",
      "Train Epoch: 2 [90880/189000 (48%)]\tLoss: 6.621612\n",
      "Train Epoch: 2 [91520/189000 (48%)]\tLoss: 6.744246\n",
      "Train Epoch: 2 [92160/189000 (49%)]\tLoss: 6.841797\n",
      "Train Epoch: 2 [92800/189000 (49%)]\tLoss: 6.642820\n",
      "Train Epoch: 2 [93440/189000 (49%)]\tLoss: 5.972005\n",
      "Train Epoch: 2 [94080/189000 (50%)]\tLoss: 6.878291\n",
      "Train Epoch: 2 [94720/189000 (50%)]\tLoss: 6.403286\n",
      "Train Epoch: 2 [95360/189000 (50%)]\tLoss: 6.697358\n",
      "Train Epoch: 2 [96000/189000 (51%)]\tLoss: 6.368679\n",
      "Train Epoch: 2 [96640/189000 (51%)]\tLoss: 6.336264\n",
      "Train Epoch: 2 [97280/189000 (51%)]\tLoss: 6.610525\n",
      "Train Epoch: 2 [97920/189000 (52%)]\tLoss: 6.546079\n",
      "Train Epoch: 2 [98560/189000 (52%)]\tLoss: 6.376884\n",
      "Train Epoch: 2 [99200/189000 (52%)]\tLoss: 6.310340\n",
      "Train Epoch: 2 [99840/189000 (53%)]\tLoss: 6.248423\n",
      "Train Epoch: 2 [100480/189000 (53%)]\tLoss: 6.541918\n",
      "Train Epoch: 2 [101120/189000 (53%)]\tLoss: 6.139272\n",
      "Train Epoch: 2 [101760/189000 (54%)]\tLoss: 6.696801\n",
      "Train Epoch: 2 [102400/189000 (54%)]\tLoss: 6.713273\n",
      "Train Epoch: 2 [103040/189000 (55%)]\tLoss: 6.841395\n",
      "Train Epoch: 2 [103680/189000 (55%)]\tLoss: 6.360784\n",
      "Train Epoch: 2 [104320/189000 (55%)]\tLoss: 6.376865\n",
      "Train Epoch: 2 [104960/189000 (56%)]\tLoss: 6.439909\n",
      "Train Epoch: 2 [105600/189000 (56%)]\tLoss: 6.504225\n",
      "Train Epoch: 2 [106240/189000 (56%)]\tLoss: 6.644649\n",
      "Train Epoch: 2 [106880/189000 (57%)]\tLoss: 6.755692\n",
      "Train Epoch: 2 [107520/189000 (57%)]\tLoss: 6.505836\n",
      "Train Epoch: 2 [108160/189000 (57%)]\tLoss: 6.674318\n",
      "Train Epoch: 2 [108800/189000 (58%)]\tLoss: 6.619018\n",
      "Train Epoch: 2 [109440/189000 (58%)]\tLoss: 6.486061\n",
      "Train Epoch: 2 [110080/189000 (58%)]\tLoss: 6.890908\n",
      "Train Epoch: 2 [110720/189000 (59%)]\tLoss: 6.533692\n",
      "Train Epoch: 2 [111360/189000 (59%)]\tLoss: 6.486050\n",
      "Train Epoch: 2 [112000/189000 (59%)]\tLoss: 6.249080\n",
      "Train Epoch: 2 [112640/189000 (60%)]\tLoss: 6.737869\n",
      "Train Epoch: 2 [113280/189000 (60%)]\tLoss: 6.657304\n",
      "Train Epoch: 2 [113920/189000 (60%)]\tLoss: 6.338218\n",
      "Train Epoch: 2 [114560/189000 (61%)]\tLoss: 6.499146\n",
      "Train Epoch: 2 [115200/189000 (61%)]\tLoss: 6.606874\n",
      "Train Epoch: 2 [115840/189000 (61%)]\tLoss: 6.690777\n",
      "Train Epoch: 2 [116480/189000 (62%)]\tLoss: 6.794367\n",
      "Train Epoch: 2 [117120/189000 (62%)]\tLoss: 6.898220\n",
      "Train Epoch: 2 [117760/189000 (62%)]\tLoss: 6.514930\n",
      "Train Epoch: 2 [118400/189000 (63%)]\tLoss: 6.046115\n",
      "Train Epoch: 2 [119040/189000 (63%)]\tLoss: 6.365091\n",
      "Train Epoch: 2 [119680/189000 (63%)]\tLoss: 6.585143\n",
      "Train Epoch: 2 [120320/189000 (64%)]\tLoss: 6.508649\n",
      "Train Epoch: 2 [120960/189000 (64%)]\tLoss: 6.698040\n",
      "Train Epoch: 2 [121600/189000 (64%)]\tLoss: 6.615150\n",
      "Train Epoch: 2 [122240/189000 (65%)]\tLoss: 6.050059\n",
      "Train Epoch: 2 [122880/189000 (65%)]\tLoss: 6.236848\n",
      "Train Epoch: 2 [123520/189000 (65%)]\tLoss: 6.336221\n",
      "Train Epoch: 2 [124160/189000 (66%)]\tLoss: 6.504998\n",
      "Train Epoch: 2 [124800/189000 (66%)]\tLoss: 6.533912\n",
      "Train Epoch: 2 [125440/189000 (66%)]\tLoss: 6.545242\n",
      "Train Epoch: 2 [126080/189000 (67%)]\tLoss: 6.504462\n",
      "Train Epoch: 2 [126720/189000 (67%)]\tLoss: 6.066552\n",
      "Train Epoch: 2 [127360/189000 (67%)]\tLoss: 6.534693\n",
      "Train Epoch: 2 [128000/189000 (68%)]\tLoss: 6.300738\n",
      "Train Epoch: 2 [128640/189000 (68%)]\tLoss: 6.627888\n",
      "Train Epoch: 2 [129280/189000 (68%)]\tLoss: 6.679381\n",
      "Train Epoch: 2 [129920/189000 (69%)]\tLoss: 6.389023\n",
      "Train Epoch: 2 [130560/189000 (69%)]\tLoss: 6.515204\n",
      "Train Epoch: 2 [131200/189000 (69%)]\tLoss: 6.320645\n",
      "Train Epoch: 2 [131840/189000 (70%)]\tLoss: 6.513523\n",
      "Train Epoch: 2 [132480/189000 (70%)]\tLoss: 6.450432\n",
      "Train Epoch: 2 [133120/189000 (70%)]\tLoss: 6.764736\n",
      "Train Epoch: 2 [133760/189000 (71%)]\tLoss: 6.547418\n",
      "Train Epoch: 2 [134400/189000 (71%)]\tLoss: 6.194460\n",
      "Train Epoch: 2 [135040/189000 (71%)]\tLoss: 6.326349\n",
      "Train Epoch: 2 [135680/189000 (72%)]\tLoss: 6.333325\n",
      "Train Epoch: 2 [136320/189000 (72%)]\tLoss: 6.365974\n",
      "Train Epoch: 2 [136960/189000 (72%)]\tLoss: 6.610005\n",
      "Train Epoch: 2 [137600/189000 (73%)]\tLoss: 6.127236\n",
      "Train Epoch: 2 [138240/189000 (73%)]\tLoss: 6.315567\n",
      "Train Epoch: 2 [138880/189000 (73%)]\tLoss: 6.620921\n",
      "Train Epoch: 2 [139520/189000 (74%)]\tLoss: 6.346707\n",
      "Train Epoch: 2 [140160/189000 (74%)]\tLoss: 6.551153\n",
      "Train Epoch: 2 [140800/189000 (74%)]\tLoss: 6.099929\n",
      "Train Epoch: 2 [141440/189000 (75%)]\tLoss: 6.458066\n",
      "Train Epoch: 2 [142080/189000 (75%)]\tLoss: 6.458954\n",
      "Train Epoch: 2 [142720/189000 (75%)]\tLoss: 6.357929\n",
      "Train Epoch: 2 [143360/189000 (76%)]\tLoss: 6.679906\n",
      "Train Epoch: 2 [144000/189000 (76%)]\tLoss: 6.633941\n",
      "Train Epoch: 2 [144640/189000 (77%)]\tLoss: 7.225496\n",
      "Train Epoch: 2 [145280/189000 (77%)]\tLoss: 6.720529\n",
      "Train Epoch: 2 [145920/189000 (77%)]\tLoss: 6.810409\n",
      "Train Epoch: 2 [146560/189000 (78%)]\tLoss: 6.694623\n",
      "Train Epoch: 2 [147200/189000 (78%)]\tLoss: 6.725679\n",
      "Train Epoch: 2 [147840/189000 (78%)]\tLoss: 6.607118\n",
      "Train Epoch: 2 [148480/189000 (79%)]\tLoss: 6.360892\n",
      "Train Epoch: 2 [149120/189000 (79%)]\tLoss: 6.409524\n",
      "Train Epoch: 2 [149760/189000 (79%)]\tLoss: 6.643495\n",
      "Train Epoch: 2 [150400/189000 (80%)]\tLoss: 6.451624\n",
      "Train Epoch: 2 [151040/189000 (80%)]\tLoss: 6.695874\n",
      "Train Epoch: 2 [151680/189000 (80%)]\tLoss: 6.923604\n",
      "Train Epoch: 2 [152320/189000 (81%)]\tLoss: 6.497139\n",
      "Train Epoch: 2 [152960/189000 (81%)]\tLoss: 6.299708\n",
      "Train Epoch: 2 [153600/189000 (81%)]\tLoss: 6.264227\n",
      "Train Epoch: 2 [154240/189000 (82%)]\tLoss: 6.669584\n",
      "Train Epoch: 2 [154880/189000 (82%)]\tLoss: 6.344196\n",
      "Train Epoch: 2 [155520/189000 (82%)]\tLoss: 6.738189\n",
      "Train Epoch: 2 [156160/189000 (83%)]\tLoss: 6.423089\n",
      "Train Epoch: 2 [156800/189000 (83%)]\tLoss: 6.722692\n",
      "Train Epoch: 2 [157440/189000 (83%)]\tLoss: 6.729291\n",
      "Train Epoch: 2 [158080/189000 (84%)]\tLoss: 6.748284\n",
      "Train Epoch: 2 [158720/189000 (84%)]\tLoss: 6.566262\n",
      "Train Epoch: 2 [159360/189000 (84%)]\tLoss: 6.508193\n",
      "Train Epoch: 2 [160000/189000 (85%)]\tLoss: 6.436886\n",
      "Train Epoch: 2 [160640/189000 (85%)]\tLoss: 6.614014\n",
      "Train Epoch: 2 [161280/189000 (85%)]\tLoss: 6.640760\n",
      "Train Epoch: 2 [161920/189000 (86%)]\tLoss: 6.768347\n",
      "Train Epoch: 2 [162560/189000 (86%)]\tLoss: 6.549657\n",
      "Train Epoch: 2 [163200/189000 (86%)]\tLoss: 6.627418\n",
      "Train Epoch: 2 [163840/189000 (87%)]\tLoss: 6.566135\n",
      "Train Epoch: 2 [164480/189000 (87%)]\tLoss: 6.529579\n",
      "Train Epoch: 2 [165120/189000 (87%)]\tLoss: 6.379847\n",
      "Train Epoch: 2 [165760/189000 (88%)]\tLoss: 6.428858\n",
      "Train Epoch: 2 [166400/189000 (88%)]\tLoss: 6.661784\n",
      "Train Epoch: 2 [167040/189000 (88%)]\tLoss: 6.400751\n",
      "Train Epoch: 2 [167680/189000 (89%)]\tLoss: 6.458239\n",
      "Train Epoch: 2 [168320/189000 (89%)]\tLoss: 6.281315\n",
      "Train Epoch: 2 [168960/189000 (89%)]\tLoss: 6.335788\n",
      "Train Epoch: 2 [169600/189000 (90%)]\tLoss: 6.564758\n",
      "Train Epoch: 2 [170240/189000 (90%)]\tLoss: 6.635862\n",
      "Train Epoch: 2 [170880/189000 (90%)]\tLoss: 6.420314\n",
      "Train Epoch: 2 [171520/189000 (91%)]\tLoss: 6.719679\n",
      "Train Epoch: 2 [172160/189000 (91%)]\tLoss: 6.651761\n",
      "Train Epoch: 2 [172800/189000 (91%)]\tLoss: 6.399716\n",
      "Train Epoch: 2 [173440/189000 (92%)]\tLoss: 6.383137\n",
      "Train Epoch: 2 [174080/189000 (92%)]\tLoss: 6.744704\n",
      "Train Epoch: 2 [174720/189000 (92%)]\tLoss: 6.932891\n",
      "Train Epoch: 2 [175360/189000 (93%)]\tLoss: 6.085955\n",
      "Train Epoch: 2 [176000/189000 (93%)]\tLoss: 6.394716\n",
      "Train Epoch: 2 [176640/189000 (93%)]\tLoss: 6.812454\n",
      "Train Epoch: 2 [177280/189000 (94%)]\tLoss: 6.523976\n",
      "Train Epoch: 2 [177920/189000 (94%)]\tLoss: 6.720612\n",
      "Train Epoch: 2 [178560/189000 (94%)]\tLoss: 6.621434\n",
      "Train Epoch: 2 [179200/189000 (95%)]\tLoss: 6.324245\n",
      "Train Epoch: 2 [179840/189000 (95%)]\tLoss: 6.428010\n",
      "Train Epoch: 2 [180480/189000 (95%)]\tLoss: 6.435745\n",
      "Train Epoch: 2 [181120/189000 (96%)]\tLoss: 6.332663\n",
      "Train Epoch: 2 [181760/189000 (96%)]\tLoss: 6.518372\n",
      "Train Epoch: 2 [182400/189000 (96%)]\tLoss: 6.658852\n",
      "Train Epoch: 2 [183040/189000 (97%)]\tLoss: 6.361406\n",
      "Train Epoch: 2 [183680/189000 (97%)]\tLoss: 6.405155\n",
      "Train Epoch: 2 [184320/189000 (97%)]\tLoss: 6.259618\n",
      "Train Epoch: 2 [184960/189000 (98%)]\tLoss: 6.269661\n",
      "Train Epoch: 2 [185600/189000 (98%)]\tLoss: 6.527628\n",
      "Train Epoch: 2 [186240/189000 (99%)]\tLoss: 6.361982\n",
      "Train Epoch: 2 [186880/189000 (99%)]\tLoss: 6.761391\n",
      "Train Epoch: 2 [187520/189000 (99%)]\tLoss: 6.485872\n",
      "Train Epoch: 2 [188160/189000 (100%)]\tLoss: 6.522303\n",
      "Train Epoch: 2 [188800/189000 (100%)]\tLoss: 6.720803\n",
      "\n",
      "Test set: Average loss: 6.3511, Accuracy: 1068/21000 (5%)\n",
      "\n",
      "Train Epoch: 3 [0/189000 (0%)]\tLoss: 6.623541\n",
      "Train Epoch: 3 [640/189000 (0%)]\tLoss: 6.513433\n",
      "Train Epoch: 3 [1280/189000 (1%)]\tLoss: 6.233186\n",
      "Train Epoch: 3 [1920/189000 (1%)]\tLoss: 6.651124\n",
      "Train Epoch: 3 [2560/189000 (1%)]\tLoss: 6.127290\n",
      "Train Epoch: 3 [3200/189000 (2%)]\tLoss: 6.683170\n",
      "Train Epoch: 3 [3840/189000 (2%)]\tLoss: 6.399198\n",
      "Train Epoch: 3 [4480/189000 (2%)]\tLoss: 6.537911\n",
      "Train Epoch: 3 [5120/189000 (3%)]\tLoss: 6.754485\n",
      "Train Epoch: 3 [5760/189000 (3%)]\tLoss: 6.722163\n",
      "Train Epoch: 3 [6400/189000 (3%)]\tLoss: 6.436009\n",
      "Train Epoch: 3 [7040/189000 (4%)]\tLoss: 6.545867\n",
      "Train Epoch: 3 [7680/189000 (4%)]\tLoss: 6.679876\n",
      "Train Epoch: 3 [8320/189000 (4%)]\tLoss: 6.447918\n",
      "Train Epoch: 3 [8960/189000 (5%)]\tLoss: 6.012363\n",
      "Train Epoch: 3 [9600/189000 (5%)]\tLoss: 6.365695\n",
      "Train Epoch: 3 [10240/189000 (5%)]\tLoss: 6.386686\n",
      "Train Epoch: 3 [10880/189000 (6%)]\tLoss: 6.694135\n",
      "Train Epoch: 3 [11520/189000 (6%)]\tLoss: 6.214912\n",
      "Train Epoch: 3 [12160/189000 (6%)]\tLoss: 6.777167\n",
      "Train Epoch: 3 [12800/189000 (7%)]\tLoss: 6.801905\n",
      "Train Epoch: 3 [13440/189000 (7%)]\tLoss: 6.014283\n",
      "Train Epoch: 3 [14080/189000 (7%)]\tLoss: 6.645463\n",
      "Train Epoch: 3 [14720/189000 (8%)]\tLoss: 6.375171\n",
      "Train Epoch: 3 [15360/189000 (8%)]\tLoss: 6.568655\n",
      "Train Epoch: 3 [16000/189000 (8%)]\tLoss: 6.617461\n",
      "Train Epoch: 3 [16640/189000 (9%)]\tLoss: 6.693531\n",
      "Train Epoch: 3 [17280/189000 (9%)]\tLoss: 6.158864\n",
      "Train Epoch: 3 [17920/189000 (9%)]\tLoss: 6.638659\n",
      "Train Epoch: 3 [18560/189000 (10%)]\tLoss: 6.425049\n",
      "Train Epoch: 3 [19200/189000 (10%)]\tLoss: 6.607852\n",
      "Train Epoch: 3 [19840/189000 (10%)]\tLoss: 6.575666\n",
      "Train Epoch: 3 [20480/189000 (11%)]\tLoss: 6.109915\n",
      "Train Epoch: 3 [21120/189000 (11%)]\tLoss: 6.166332\n",
      "Train Epoch: 3 [21760/189000 (12%)]\tLoss: 6.661168\n",
      "Train Epoch: 3 [22400/189000 (12%)]\tLoss: 6.444408\n",
      "Train Epoch: 3 [23040/189000 (12%)]\tLoss: 6.457398\n",
      "Train Epoch: 3 [23680/189000 (13%)]\tLoss: 6.301162\n",
      "Train Epoch: 3 [24320/189000 (13%)]\tLoss: 6.294667\n",
      "Train Epoch: 3 [24960/189000 (13%)]\tLoss: 6.489711\n",
      "Train Epoch: 3 [25600/189000 (14%)]\tLoss: 6.196071\n",
      "Train Epoch: 3 [26240/189000 (14%)]\tLoss: 6.290281\n",
      "Train Epoch: 3 [26880/189000 (14%)]\tLoss: 6.266654\n",
      "Train Epoch: 3 [27520/189000 (15%)]\tLoss: 6.410520\n",
      "Train Epoch: 3 [28160/189000 (15%)]\tLoss: 6.852440\n",
      "Train Epoch: 3 [28800/189000 (15%)]\tLoss: 6.425401\n",
      "Train Epoch: 3 [29440/189000 (16%)]\tLoss: 6.568121\n",
      "Train Epoch: 3 [30080/189000 (16%)]\tLoss: 6.343784\n",
      "Train Epoch: 3 [30720/189000 (16%)]\tLoss: 6.655460\n",
      "Train Epoch: 3 [31360/189000 (17%)]\tLoss: 6.553464\n",
      "Train Epoch: 3 [32000/189000 (17%)]\tLoss: 6.501946\n",
      "Train Epoch: 3 [32640/189000 (17%)]\tLoss: 6.539931\n",
      "Train Epoch: 3 [33280/189000 (18%)]\tLoss: 6.074341\n",
      "Train Epoch: 3 [33920/189000 (18%)]\tLoss: 6.378501\n",
      "Train Epoch: 3 [34560/189000 (18%)]\tLoss: 6.425774\n",
      "Train Epoch: 3 [35200/189000 (19%)]\tLoss: 6.817899\n",
      "Train Epoch: 3 [35840/189000 (19%)]\tLoss: 6.806117\n",
      "Train Epoch: 3 [36480/189000 (19%)]\tLoss: 6.483201\n",
      "Train Epoch: 3 [37120/189000 (20%)]\tLoss: 6.643265\n",
      "Train Epoch: 3 [37760/189000 (20%)]\tLoss: 6.521139\n",
      "Train Epoch: 3 [38400/189000 (20%)]\tLoss: 6.197352\n",
      "Train Epoch: 3 [39040/189000 (21%)]\tLoss: 6.500859\n",
      "Train Epoch: 3 [39680/189000 (21%)]\tLoss: 6.543534\n",
      "Train Epoch: 3 [40320/189000 (21%)]\tLoss: 6.228372\n",
      "Train Epoch: 3 [40960/189000 (22%)]\tLoss: 6.546929\n",
      "Train Epoch: 3 [41600/189000 (22%)]\tLoss: 6.299810\n",
      "Train Epoch: 3 [42240/189000 (22%)]\tLoss: 6.420594\n",
      "Train Epoch: 3 [42880/189000 (23%)]\tLoss: 6.641257\n",
      "Train Epoch: 3 [43520/189000 (23%)]\tLoss: 6.601774\n",
      "Train Epoch: 3 [44160/189000 (23%)]\tLoss: 6.665964\n",
      "Train Epoch: 3 [44800/189000 (24%)]\tLoss: 6.942521\n",
      "Train Epoch: 3 [45440/189000 (24%)]\tLoss: 6.541864\n",
      "Train Epoch: 3 [46080/189000 (24%)]\tLoss: 6.484457\n",
      "Train Epoch: 3 [46720/189000 (25%)]\tLoss: 6.263652\n",
      "Train Epoch: 3 [47360/189000 (25%)]\tLoss: 6.664035\n",
      "Train Epoch: 3 [48000/189000 (25%)]\tLoss: 6.612553\n",
      "Train Epoch: 3 [48640/189000 (26%)]\tLoss: 6.425848\n",
      "Train Epoch: 3 [49280/189000 (26%)]\tLoss: 6.819673\n",
      "Train Epoch: 3 [49920/189000 (26%)]\tLoss: 6.338082\n",
      "Train Epoch: 3 [50560/189000 (27%)]\tLoss: 6.611176\n",
      "Train Epoch: 3 [51200/189000 (27%)]\tLoss: 6.779626\n",
      "Train Epoch: 3 [51840/189000 (27%)]\tLoss: 6.587845\n",
      "Train Epoch: 3 [52480/189000 (28%)]\tLoss: 6.174456\n",
      "Train Epoch: 3 [53120/189000 (28%)]\tLoss: 6.608209\n",
      "Train Epoch: 3 [53760/189000 (28%)]\tLoss: 6.496361\n",
      "Train Epoch: 3 [54400/189000 (29%)]\tLoss: 6.445056\n",
      "Train Epoch: 3 [55040/189000 (29%)]\tLoss: 6.060661\n",
      "Train Epoch: 3 [55680/189000 (29%)]\tLoss: 6.392527\n",
      "Train Epoch: 3 [56320/189000 (30%)]\tLoss: 6.513535\n",
      "Train Epoch: 3 [56960/189000 (30%)]\tLoss: 6.886880\n",
      "Train Epoch: 3 [57600/189000 (30%)]\tLoss: 6.845802\n",
      "Train Epoch: 3 [58240/189000 (31%)]\tLoss: 6.305769\n",
      "Train Epoch: 3 [58880/189000 (31%)]\tLoss: 6.373030\n",
      "Train Epoch: 3 [59520/189000 (31%)]\tLoss: 6.173615\n",
      "Train Epoch: 3 [60160/189000 (32%)]\tLoss: 6.587260\n",
      "Train Epoch: 3 [60800/189000 (32%)]\tLoss: 6.488715\n",
      "Train Epoch: 3 [61440/189000 (32%)]\tLoss: 6.246254\n",
      "Train Epoch: 3 [62080/189000 (33%)]\tLoss: 6.303888\n",
      "Train Epoch: 3 [62720/189000 (33%)]\tLoss: 6.489526\n",
      "Train Epoch: 3 [63360/189000 (34%)]\tLoss: 6.422252\n",
      "Train Epoch: 3 [64000/189000 (34%)]\tLoss: 6.902678\n",
      "Train Epoch: 3 [64640/189000 (34%)]\tLoss: 6.197505\n",
      "Train Epoch: 3 [65280/189000 (35%)]\tLoss: 6.518878\n",
      "Train Epoch: 3 [65920/189000 (35%)]\tLoss: 6.331471\n",
      "Train Epoch: 3 [66560/189000 (35%)]\tLoss: 6.294086\n",
      "Train Epoch: 3 [67200/189000 (36%)]\tLoss: 6.347824\n",
      "Train Epoch: 3 [67840/189000 (36%)]\tLoss: 6.287544\n",
      "Train Epoch: 3 [68480/189000 (36%)]\tLoss: 6.431350\n",
      "Train Epoch: 3 [69120/189000 (37%)]\tLoss: 6.485889\n",
      "Train Epoch: 3 [69760/189000 (37%)]\tLoss: 6.461657\n",
      "Train Epoch: 3 [70400/189000 (37%)]\tLoss: 6.705157\n",
      "Train Epoch: 3 [71040/189000 (38%)]\tLoss: 6.484375\n",
      "Train Epoch: 3 [71680/189000 (38%)]\tLoss: 6.480055\n",
      "Train Epoch: 3 [72320/189000 (38%)]\tLoss: 6.332685\n",
      "Train Epoch: 3 [72960/189000 (39%)]\tLoss: 6.724676\n",
      "Train Epoch: 3 [73600/189000 (39%)]\tLoss: 6.390969\n",
      "Train Epoch: 3 [74240/189000 (39%)]\tLoss: 6.035203\n",
      "Train Epoch: 3 [74880/189000 (40%)]\tLoss: 6.704811\n",
      "Train Epoch: 3 [75520/189000 (40%)]\tLoss: 6.464555\n",
      "Train Epoch: 3 [76160/189000 (40%)]\tLoss: 6.369596\n",
      "Train Epoch: 3 [76800/189000 (41%)]\tLoss: 6.444052\n",
      "Train Epoch: 3 [77440/189000 (41%)]\tLoss: 6.250339\n",
      "Train Epoch: 3 [78080/189000 (41%)]\tLoss: 6.382420\n",
      "Train Epoch: 3 [78720/189000 (42%)]\tLoss: 6.575915\n",
      "Train Epoch: 3 [79360/189000 (42%)]\tLoss: 6.481825\n",
      "Train Epoch: 3 [80000/189000 (42%)]\tLoss: 6.377729\n",
      "Train Epoch: 3 [80640/189000 (43%)]\tLoss: 6.338496\n",
      "Train Epoch: 3 [81280/189000 (43%)]\tLoss: 6.827780\n",
      "Train Epoch: 3 [81920/189000 (43%)]\tLoss: 6.675049\n",
      "Train Epoch: 3 [82560/189000 (44%)]\tLoss: 6.515142\n",
      "Train Epoch: 3 [83200/189000 (44%)]\tLoss: 6.355369\n",
      "Train Epoch: 3 [83840/189000 (44%)]\tLoss: 6.791290\n",
      "Train Epoch: 3 [84480/189000 (45%)]\tLoss: 6.466920\n",
      "Train Epoch: 3 [85120/189000 (45%)]\tLoss: 6.598633\n",
      "Train Epoch: 3 [85760/189000 (45%)]\tLoss: 6.264342\n",
      "Train Epoch: 3 [86400/189000 (46%)]\tLoss: 6.340353\n",
      "Train Epoch: 3 [87040/189000 (46%)]\tLoss: 6.391164\n",
      "Train Epoch: 3 [87680/189000 (46%)]\tLoss: 6.860115\n",
      "Train Epoch: 3 [88320/189000 (47%)]\tLoss: 6.867142\n",
      "Train Epoch: 3 [88960/189000 (47%)]\tLoss: 6.281224\n",
      "Train Epoch: 3 [89600/189000 (47%)]\tLoss: 6.646207\n",
      "Train Epoch: 3 [90240/189000 (48%)]\tLoss: 6.572399\n",
      "Train Epoch: 3 [90880/189000 (48%)]\tLoss: 6.952655\n",
      "Train Epoch: 3 [91520/189000 (48%)]\tLoss: 6.894200\n",
      "Train Epoch: 3 [92160/189000 (49%)]\tLoss: 6.478490\n",
      "Train Epoch: 3 [92800/189000 (49%)]\tLoss: 6.473416\n",
      "Train Epoch: 3 [93440/189000 (49%)]\tLoss: 6.275850\n",
      "Train Epoch: 3 [94080/189000 (50%)]\tLoss: 6.517193\n",
      "Train Epoch: 3 [94720/189000 (50%)]\tLoss: 6.099932\n",
      "Train Epoch: 3 [95360/189000 (50%)]\tLoss: 6.934848\n",
      "Train Epoch: 3 [96000/189000 (51%)]\tLoss: 6.142787\n",
      "Train Epoch: 3 [96640/189000 (51%)]\tLoss: 6.381264\n",
      "Train Epoch: 3 [97280/189000 (51%)]\tLoss: 5.997184\n",
      "Train Epoch: 3 [97920/189000 (52%)]\tLoss: 6.639958\n",
      "Train Epoch: 3 [98560/189000 (52%)]\tLoss: 6.149397\n",
      "Train Epoch: 3 [99200/189000 (52%)]\tLoss: 6.263259\n",
      "Train Epoch: 3 [99840/189000 (53%)]\tLoss: 6.599591\n",
      "Train Epoch: 3 [100480/189000 (53%)]\tLoss: 6.357532\n",
      "Train Epoch: 3 [101120/189000 (53%)]\tLoss: 6.186361\n",
      "Train Epoch: 3 [101760/189000 (54%)]\tLoss: 6.402050\n",
      "Train Epoch: 3 [102400/189000 (54%)]\tLoss: 6.251178\n",
      "Train Epoch: 3 [103040/189000 (55%)]\tLoss: 6.453361\n",
      "Train Epoch: 3 [103680/189000 (55%)]\tLoss: 6.592408\n",
      "Train Epoch: 3 [104320/189000 (55%)]\tLoss: 6.634545\n",
      "Train Epoch: 3 [104960/189000 (56%)]\tLoss: 6.261113\n",
      "Train Epoch: 3 [105600/189000 (56%)]\tLoss: 6.467342\n",
      "Train Epoch: 3 [106240/189000 (56%)]\tLoss: 6.789334\n",
      "Train Epoch: 3 [106880/189000 (57%)]\tLoss: 6.541234\n",
      "Train Epoch: 3 [107520/189000 (57%)]\tLoss: 6.383101\n",
      "Train Epoch: 3 [108160/189000 (57%)]\tLoss: 6.835138\n",
      "Train Epoch: 3 [108800/189000 (58%)]\tLoss: 6.253797\n",
      "Train Epoch: 3 [109440/189000 (58%)]\tLoss: 6.518715\n",
      "Train Epoch: 3 [110080/189000 (58%)]\tLoss: 6.851024\n",
      "Train Epoch: 3 [110720/189000 (59%)]\tLoss: 6.480161\n",
      "Train Epoch: 3 [111360/189000 (59%)]\tLoss: 6.784898\n",
      "Train Epoch: 3 [112000/189000 (59%)]\tLoss: 6.830117\n",
      "Train Epoch: 3 [112640/189000 (60%)]\tLoss: 5.951042\n",
      "Train Epoch: 3 [113280/189000 (60%)]\tLoss: 6.330164\n",
      "Train Epoch: 3 [113920/189000 (60%)]\tLoss: 6.719302\n",
      "Train Epoch: 3 [114560/189000 (61%)]\tLoss: 6.262238\n",
      "Train Epoch: 3 [115200/189000 (61%)]\tLoss: 6.826279\n",
      "Train Epoch: 3 [115840/189000 (61%)]\tLoss: 6.085082\n",
      "Train Epoch: 3 [116480/189000 (62%)]\tLoss: 6.161015\n",
      "Train Epoch: 3 [117120/189000 (62%)]\tLoss: 6.513871\n",
      "Train Epoch: 3 [117760/189000 (62%)]\tLoss: 6.675221\n",
      "Train Epoch: 3 [118400/189000 (63%)]\tLoss: 6.402484\n",
      "Train Epoch: 3 [119040/189000 (63%)]\tLoss: 6.418787\n",
      "Train Epoch: 3 [119680/189000 (63%)]\tLoss: 6.709666\n",
      "Train Epoch: 3 [120320/189000 (64%)]\tLoss: 6.464663\n",
      "Train Epoch: 3 [120960/189000 (64%)]\tLoss: 6.201211\n",
      "Train Epoch: 3 [121600/189000 (64%)]\tLoss: 6.058414\n",
      "Train Epoch: 3 [122240/189000 (65%)]\tLoss: 5.945833\n",
      "Train Epoch: 3 [122880/189000 (65%)]\tLoss: 6.540509\n",
      "Train Epoch: 3 [123520/189000 (65%)]\tLoss: 6.785344\n",
      "Train Epoch: 3 [124160/189000 (66%)]\tLoss: 6.514070\n",
      "Train Epoch: 3 [124800/189000 (66%)]\tLoss: 6.947049\n",
      "Train Epoch: 3 [125440/189000 (66%)]\tLoss: 6.569649\n",
      "Train Epoch: 3 [126080/189000 (67%)]\tLoss: 7.043585\n",
      "Train Epoch: 3 [126720/189000 (67%)]\tLoss: 6.680374\n",
      "Train Epoch: 3 [127360/189000 (67%)]\tLoss: 6.338467\n",
      "Train Epoch: 3 [128000/189000 (68%)]\tLoss: 6.612695\n",
      "Train Epoch: 3 [128640/189000 (68%)]\tLoss: 6.334651\n",
      "Train Epoch: 3 [129280/189000 (68%)]\tLoss: 6.277085\n",
      "Train Epoch: 3 [129920/189000 (69%)]\tLoss: 6.337291\n",
      "Train Epoch: 3 [130560/189000 (69%)]\tLoss: 6.432042\n",
      "Train Epoch: 3 [131200/189000 (69%)]\tLoss: 6.716468\n",
      "Train Epoch: 3 [131840/189000 (70%)]\tLoss: 6.590807\n",
      "Train Epoch: 3 [132480/189000 (70%)]\tLoss: 6.455952\n",
      "Train Epoch: 3 [133120/189000 (70%)]\tLoss: 6.513300\n",
      "Train Epoch: 3 [133760/189000 (71%)]\tLoss: 6.149471\n",
      "Train Epoch: 3 [134400/189000 (71%)]\tLoss: 6.357441\n",
      "Train Epoch: 3 [135040/189000 (71%)]\tLoss: 6.581470\n",
      "Train Epoch: 3 [135680/189000 (72%)]\tLoss: 6.471684\n",
      "Train Epoch: 3 [136320/189000 (72%)]\tLoss: 6.629811\n",
      "Train Epoch: 3 [136960/189000 (72%)]\tLoss: 6.628866\n",
      "Train Epoch: 3 [137600/189000 (73%)]\tLoss: 6.361452\n",
      "Train Epoch: 3 [138240/189000 (73%)]\tLoss: 6.443075\n",
      "Train Epoch: 3 [138880/189000 (73%)]\tLoss: 6.643402\n",
      "Train Epoch: 3 [139520/189000 (74%)]\tLoss: 6.578736\n",
      "Train Epoch: 3 [140160/189000 (74%)]\tLoss: 6.781683\n",
      "Train Epoch: 3 [140800/189000 (74%)]\tLoss: 6.727558\n",
      "Train Epoch: 3 [141440/189000 (75%)]\tLoss: 6.598614\n",
      "Train Epoch: 3 [142080/189000 (75%)]\tLoss: 6.706662\n",
      "Train Epoch: 3 [142720/189000 (75%)]\tLoss: 6.541701\n",
      "Train Epoch: 3 [143360/189000 (76%)]\tLoss: 6.195854\n",
      "Train Epoch: 3 [144000/189000 (76%)]\tLoss: 6.691849\n",
      "Train Epoch: 3 [144640/189000 (77%)]\tLoss: 6.643755\n",
      "Train Epoch: 3 [145280/189000 (77%)]\tLoss: 6.830950\n",
      "Train Epoch: 3 [145920/189000 (77%)]\tLoss: 6.327251\n",
      "Train Epoch: 3 [146560/189000 (78%)]\tLoss: 6.503858\n",
      "Train Epoch: 3 [147200/189000 (78%)]\tLoss: 6.482863\n",
      "Train Epoch: 3 [147840/189000 (78%)]\tLoss: 6.533803\n",
      "Train Epoch: 3 [148480/189000 (79%)]\tLoss: 6.408203\n",
      "Train Epoch: 3 [149120/189000 (79%)]\tLoss: 6.572789\n",
      "Train Epoch: 3 [149760/189000 (79%)]\tLoss: 6.761856\n",
      "Train Epoch: 3 [150400/189000 (80%)]\tLoss: 6.535503\n",
      "Train Epoch: 3 [151040/189000 (80%)]\tLoss: 6.380766\n",
      "Train Epoch: 3 [151680/189000 (80%)]\tLoss: 6.621097\n",
      "Train Epoch: 3 [152320/189000 (81%)]\tLoss: 6.217467\n",
      "Train Epoch: 3 [152960/189000 (81%)]\tLoss: 6.490114\n",
      "Train Epoch: 3 [153600/189000 (81%)]\tLoss: 6.538316\n",
      "Train Epoch: 3 [154240/189000 (82%)]\tLoss: 7.012742\n",
      "Train Epoch: 3 [154880/189000 (82%)]\tLoss: 6.668384\n",
      "Train Epoch: 3 [155520/189000 (82%)]\tLoss: 6.501071\n",
      "Train Epoch: 3 [156160/189000 (83%)]\tLoss: 5.951858\n",
      "Train Epoch: 3 [156800/189000 (83%)]\tLoss: 6.593120\n",
      "Train Epoch: 3 [157440/189000 (83%)]\tLoss: 6.351428\n",
      "Train Epoch: 3 [158080/189000 (84%)]\tLoss: 6.183174\n",
      "Train Epoch: 3 [158720/189000 (84%)]\tLoss: 6.444844\n",
      "Train Epoch: 3 [159360/189000 (84%)]\tLoss: 6.651151\n",
      "Train Epoch: 3 [160000/189000 (85%)]\tLoss: 6.206084\n",
      "Train Epoch: 3 [160640/189000 (85%)]\tLoss: 6.298016\n",
      "Train Epoch: 3 [161280/189000 (85%)]\tLoss: 6.359462\n",
      "Train Epoch: 3 [161920/189000 (86%)]\tLoss: 6.680003\n",
      "Train Epoch: 3 [162560/189000 (86%)]\tLoss: 6.724272\n",
      "Train Epoch: 3 [163200/189000 (86%)]\tLoss: 6.464673\n",
      "Train Epoch: 3 [163840/189000 (87%)]\tLoss: 6.401181\n",
      "Train Epoch: 3 [164480/189000 (87%)]\tLoss: 6.438691\n",
      "Train Epoch: 3 [165120/189000 (87%)]\tLoss: 6.441542\n",
      "Train Epoch: 3 [165760/189000 (88%)]\tLoss: 6.532046\n",
      "Train Epoch: 3 [166400/189000 (88%)]\tLoss: 6.803979\n",
      "Train Epoch: 3 [167040/189000 (88%)]\tLoss: 6.008236\n",
      "Train Epoch: 3 [167680/189000 (89%)]\tLoss: 6.503868\n",
      "Train Epoch: 3 [168320/189000 (89%)]\tLoss: 6.592789\n",
      "Train Epoch: 3 [168960/189000 (89%)]\tLoss: 6.504889\n",
      "Train Epoch: 3 [169600/189000 (90%)]\tLoss: 6.590381\n",
      "Train Epoch: 3 [170240/189000 (90%)]\tLoss: 6.539056\n",
      "Train Epoch: 3 [170880/189000 (90%)]\tLoss: 6.554733\n",
      "Train Epoch: 3 [171520/189000 (91%)]\tLoss: 6.637976\n",
      "Train Epoch: 3 [172160/189000 (91%)]\tLoss: 6.849911\n",
      "Train Epoch: 3 [172800/189000 (91%)]\tLoss: 6.318919\n",
      "Train Epoch: 3 [173440/189000 (92%)]\tLoss: 6.468848\n",
      "Train Epoch: 3 [174080/189000 (92%)]\tLoss: 6.324766\n",
      "Train Epoch: 3 [174720/189000 (92%)]\tLoss: 6.541409\n",
      "Train Epoch: 3 [175360/189000 (93%)]\tLoss: 6.540034\n",
      "Train Epoch: 3 [176000/189000 (93%)]\tLoss: 6.634173\n",
      "Train Epoch: 3 [176640/189000 (93%)]\tLoss: 6.576221\n",
      "Train Epoch: 3 [177280/189000 (94%)]\tLoss: 6.553271\n",
      "Train Epoch: 3 [177920/189000 (94%)]\tLoss: 6.351063\n",
      "Train Epoch: 3 [178560/189000 (94%)]\tLoss: 6.583503\n",
      "Train Epoch: 3 [179200/189000 (95%)]\tLoss: 6.607212\n",
      "Train Epoch: 3 [179840/189000 (95%)]\tLoss: 6.548004\n",
      "Train Epoch: 3 [180480/189000 (95%)]\tLoss: 6.763238\n",
      "Train Epoch: 3 [181120/189000 (96%)]\tLoss: 6.689721\n",
      "Train Epoch: 3 [181760/189000 (96%)]\tLoss: 6.511640\n",
      "Train Epoch: 3 [182400/189000 (96%)]\tLoss: 6.274717\n",
      "Train Epoch: 3 [183040/189000 (97%)]\tLoss: 6.544587\n",
      "Train Epoch: 3 [183680/189000 (97%)]\tLoss: 6.526692\n",
      "Train Epoch: 3 [184320/189000 (97%)]\tLoss: 6.373055\n",
      "Train Epoch: 3 [184960/189000 (98%)]\tLoss: 5.991632\n",
      "Train Epoch: 3 [185600/189000 (98%)]\tLoss: 6.403919\n",
      "Train Epoch: 3 [186240/189000 (99%)]\tLoss: 6.934288\n",
      "Train Epoch: 3 [186880/189000 (99%)]\tLoss: 6.607952\n",
      "Train Epoch: 3 [187520/189000 (99%)]\tLoss: 6.641263\n",
      "Train Epoch: 3 [188160/189000 (100%)]\tLoss: 6.453454\n",
      "Train Epoch: 3 [188800/189000 (100%)]\tLoss: 6.934812\n",
      "\n",
      "Test set: Average loss: 6.3319, Accuracy: 1179/21000 (6%)\n",
      "\n",
      "Train Epoch: 4 [0/189000 (0%)]\tLoss: 6.922938\n",
      "Train Epoch: 4 [640/189000 (0%)]\tLoss: 6.423273\n",
      "Train Epoch: 4 [1280/189000 (1%)]\tLoss: 6.504781\n",
      "Train Epoch: 4 [1920/189000 (1%)]\tLoss: 6.248559\n",
      "Train Epoch: 4 [2560/189000 (1%)]\tLoss: 6.427309\n",
      "Train Epoch: 4 [3200/189000 (2%)]\tLoss: 6.351480\n",
      "Train Epoch: 4 [3840/189000 (2%)]\tLoss: 6.552219\n",
      "Train Epoch: 4 [4480/189000 (2%)]\tLoss: 6.492161\n",
      "Train Epoch: 4 [5120/189000 (3%)]\tLoss: 6.296345\n",
      "Train Epoch: 4 [5760/189000 (3%)]\tLoss: 6.497492\n",
      "Train Epoch: 4 [6400/189000 (3%)]\tLoss: 6.770921\n",
      "Train Epoch: 4 [7040/189000 (4%)]\tLoss: 6.622028\n",
      "Train Epoch: 4 [7680/189000 (4%)]\tLoss: 6.572515\n",
      "Train Epoch: 4 [8320/189000 (4%)]\tLoss: 6.569618\n",
      "Train Epoch: 4 [8960/189000 (5%)]\tLoss: 6.215035\n",
      "Train Epoch: 4 [9600/189000 (5%)]\tLoss: 6.101847\n",
      "Train Epoch: 4 [10240/189000 (5%)]\tLoss: 6.622506\n",
      "Train Epoch: 4 [10880/189000 (6%)]\tLoss: 6.490149\n",
      "Train Epoch: 4 [11520/189000 (6%)]\tLoss: 6.391884\n",
      "Train Epoch: 4 [12160/189000 (6%)]\tLoss: 6.121727\n",
      "Train Epoch: 4 [12800/189000 (7%)]\tLoss: 6.575156\n",
      "Train Epoch: 4 [13440/189000 (7%)]\tLoss: 6.724601\n",
      "Train Epoch: 4 [14080/189000 (7%)]\tLoss: 6.683794\n",
      "Train Epoch: 4 [14720/189000 (8%)]\tLoss: 6.433895\n",
      "Train Epoch: 4 [15360/189000 (8%)]\tLoss: 6.833352\n",
      "Train Epoch: 4 [16000/189000 (8%)]\tLoss: 6.298096\n",
      "Train Epoch: 4 [16640/189000 (9%)]\tLoss: 6.835576\n",
      "Train Epoch: 4 [17280/189000 (9%)]\tLoss: 6.634929\n",
      "Train Epoch: 4 [17920/189000 (9%)]\tLoss: 6.860545\n",
      "Train Epoch: 4 [18560/189000 (10%)]\tLoss: 6.656621\n",
      "Train Epoch: 4 [19200/189000 (10%)]\tLoss: 6.688707\n",
      "Train Epoch: 4 [19840/189000 (10%)]\tLoss: 6.302341\n",
      "Train Epoch: 4 [20480/189000 (11%)]\tLoss: 6.602521\n",
      "Train Epoch: 4 [21120/189000 (11%)]\tLoss: 6.167660\n",
      "Train Epoch: 4 [21760/189000 (12%)]\tLoss: 6.333180\n",
      "Train Epoch: 4 [22400/189000 (12%)]\tLoss: 6.537934\n",
      "Train Epoch: 4 [23040/189000 (12%)]\tLoss: 6.322530\n",
      "Train Epoch: 4 [23680/189000 (13%)]\tLoss: 6.571632\n",
      "Train Epoch: 4 [24320/189000 (13%)]\tLoss: 6.207596\n",
      "Train Epoch: 4 [24960/189000 (13%)]\tLoss: 6.504795\n",
      "Train Epoch: 4 [25600/189000 (14%)]\tLoss: 6.626053\n",
      "Train Epoch: 4 [26240/189000 (14%)]\tLoss: 5.918407\n",
      "Train Epoch: 4 [26880/189000 (14%)]\tLoss: 6.647963\n",
      "Train Epoch: 4 [27520/189000 (15%)]\tLoss: 6.171357\n",
      "Train Epoch: 4 [28160/189000 (15%)]\tLoss: 6.788624\n",
      "Train Epoch: 4 [28800/189000 (15%)]\tLoss: 6.413661\n",
      "Train Epoch: 4 [29440/189000 (16%)]\tLoss: 6.513191\n",
      "Train Epoch: 4 [30080/189000 (16%)]\tLoss: 6.559355\n",
      "Train Epoch: 4 [30720/189000 (16%)]\tLoss: 6.009006\n",
      "Train Epoch: 4 [31360/189000 (17%)]\tLoss: 6.816152\n",
      "Train Epoch: 4 [32000/189000 (17%)]\tLoss: 6.505174\n",
      "Train Epoch: 4 [32640/189000 (17%)]\tLoss: 6.454521\n",
      "Train Epoch: 4 [33280/189000 (18%)]\tLoss: 6.601263\n",
      "Train Epoch: 4 [33920/189000 (18%)]\tLoss: 6.330150\n",
      "Train Epoch: 4 [34560/189000 (18%)]\tLoss: 6.398601\n",
      "Train Epoch: 4 [35200/189000 (19%)]\tLoss: 6.422574\n",
      "Train Epoch: 4 [35840/189000 (19%)]\tLoss: 6.739077\n",
      "Train Epoch: 4 [36480/189000 (19%)]\tLoss: 6.198571\n",
      "Train Epoch: 4 [37120/189000 (20%)]\tLoss: 6.249314\n",
      "Train Epoch: 4 [37760/189000 (20%)]\tLoss: 6.447567\n",
      "Train Epoch: 4 [38400/189000 (20%)]\tLoss: 6.543137\n",
      "Train Epoch: 4 [39040/189000 (21%)]\tLoss: 6.723720\n",
      "Train Epoch: 4 [39680/189000 (21%)]\tLoss: 6.197095\n",
      "Train Epoch: 4 [40320/189000 (21%)]\tLoss: 6.430037\n",
      "Train Epoch: 4 [40960/189000 (22%)]\tLoss: 6.805335\n",
      "Train Epoch: 4 [41600/189000 (22%)]\tLoss: 6.617087\n",
      "Train Epoch: 4 [42240/189000 (22%)]\tLoss: 6.907311\n",
      "Train Epoch: 4 [42880/189000 (23%)]\tLoss: 6.471030\n",
      "Train Epoch: 4 [43520/189000 (23%)]\tLoss: 6.520988\n",
      "Train Epoch: 4 [44160/189000 (23%)]\tLoss: 6.439677\n",
      "Train Epoch: 4 [44800/189000 (24%)]\tLoss: 6.634648\n",
      "Train Epoch: 4 [45440/189000 (24%)]\tLoss: 5.998748\n",
      "Train Epoch: 4 [46080/189000 (24%)]\tLoss: 6.062137\n",
      "Train Epoch: 4 [46720/189000 (25%)]\tLoss: 6.576850\n",
      "Train Epoch: 4 [47360/189000 (25%)]\tLoss: 6.364905\n",
      "Train Epoch: 4 [48000/189000 (25%)]\tLoss: 6.637405\n",
      "Train Epoch: 4 [48640/189000 (26%)]\tLoss: 6.399596\n",
      "Train Epoch: 4 [49280/189000 (26%)]\tLoss: 6.347498\n",
      "Train Epoch: 4 [49920/189000 (26%)]\tLoss: 6.753557\n",
      "Train Epoch: 4 [50560/189000 (27%)]\tLoss: 6.496715\n",
      "Train Epoch: 4 [51200/189000 (27%)]\tLoss: 6.448956\n",
      "Train Epoch: 4 [51840/189000 (27%)]\tLoss: 6.205320\n",
      "Train Epoch: 4 [52480/189000 (28%)]\tLoss: 6.328974\n",
      "Train Epoch: 4 [53120/189000 (28%)]\tLoss: 6.562666\n",
      "Train Epoch: 4 [53760/189000 (28%)]\tLoss: 6.187314\n",
      "Train Epoch: 4 [54400/189000 (29%)]\tLoss: 6.205422\n",
      "Train Epoch: 4 [55040/189000 (29%)]\tLoss: 5.803387\n",
      "Train Epoch: 4 [55680/189000 (29%)]\tLoss: 6.452099\n",
      "Train Epoch: 4 [56320/189000 (30%)]\tLoss: 5.911690\n",
      "Train Epoch: 4 [56960/189000 (30%)]\tLoss: 6.291574\n",
      "Train Epoch: 4 [57600/189000 (30%)]\tLoss: 6.395051\n",
      "Train Epoch: 4 [58240/189000 (31%)]\tLoss: 6.429338\n",
      "Train Epoch: 4 [58880/189000 (31%)]\tLoss: 6.460393\n",
      "Train Epoch: 4 [59520/189000 (31%)]\tLoss: 6.518864\n",
      "Train Epoch: 4 [60160/189000 (32%)]\tLoss: 6.050402\n",
      "Train Epoch: 4 [60800/189000 (32%)]\tLoss: 6.047480\n",
      "Train Epoch: 4 [61440/189000 (32%)]\tLoss: 6.437983\n",
      "Train Epoch: 4 [62080/189000 (33%)]\tLoss: 6.680603\n",
      "Train Epoch: 4 [62720/189000 (33%)]\tLoss: 6.813159\n",
      "Train Epoch: 4 [63360/189000 (34%)]\tLoss: 6.908705\n",
      "Train Epoch: 4 [64000/189000 (34%)]\tLoss: 6.310898\n",
      "Train Epoch: 4 [64640/189000 (34%)]\tLoss: 6.603450\n",
      "Train Epoch: 4 [65280/189000 (35%)]\tLoss: 6.516562\n",
      "Train Epoch: 4 [65920/189000 (35%)]\tLoss: 6.566956\n",
      "Train Epoch: 4 [66560/189000 (35%)]\tLoss: 6.698340\n",
      "Train Epoch: 4 [67200/189000 (36%)]\tLoss: 6.697744\n",
      "Train Epoch: 4 [67840/189000 (36%)]\tLoss: 6.587354\n",
      "Train Epoch: 4 [68480/189000 (36%)]\tLoss: 6.325201\n",
      "Train Epoch: 4 [69120/189000 (37%)]\tLoss: 6.416825\n",
      "Train Epoch: 4 [69760/189000 (37%)]\tLoss: 6.426660\n",
      "Train Epoch: 4 [70400/189000 (37%)]\tLoss: 6.483864\n",
      "Train Epoch: 4 [71040/189000 (38%)]\tLoss: 6.293539\n",
      "Train Epoch: 4 [71680/189000 (38%)]\tLoss: 6.440153\n",
      "Train Epoch: 4 [72320/189000 (38%)]\tLoss: 6.550504\n",
      "Train Epoch: 4 [72960/189000 (39%)]\tLoss: 6.769686\n",
      "Train Epoch: 4 [73600/189000 (39%)]\tLoss: 6.676602\n",
      "Train Epoch: 4 [74240/189000 (39%)]\tLoss: 6.560508\n",
      "Train Epoch: 4 [74880/189000 (40%)]\tLoss: 6.192119\n",
      "Train Epoch: 4 [75520/189000 (40%)]\tLoss: 6.142347\n",
      "Train Epoch: 4 [76160/189000 (40%)]\tLoss: 5.982182\n",
      "Train Epoch: 4 [76800/189000 (41%)]\tLoss: 6.406342\n",
      "Train Epoch: 4 [77440/189000 (41%)]\tLoss: 6.401839\n",
      "Train Epoch: 4 [78080/189000 (41%)]\tLoss: 6.470619\n",
      "Train Epoch: 4 [78720/189000 (42%)]\tLoss: 6.665549\n",
      "Train Epoch: 4 [79360/189000 (42%)]\tLoss: 6.378492\n",
      "Train Epoch: 4 [80000/189000 (42%)]\tLoss: 6.769835\n",
      "Train Epoch: 4 [80640/189000 (43%)]\tLoss: 6.594910\n",
      "Train Epoch: 4 [81280/189000 (43%)]\tLoss: 6.328692\n",
      "Train Epoch: 4 [81920/189000 (43%)]\tLoss: 6.503376\n",
      "Train Epoch: 4 [82560/189000 (44%)]\tLoss: 6.539995\n",
      "Train Epoch: 4 [83200/189000 (44%)]\tLoss: 6.483031\n",
      "Train Epoch: 4 [83840/189000 (44%)]\tLoss: 5.927207\n",
      "Train Epoch: 4 [84480/189000 (45%)]\tLoss: 6.640362\n",
      "Train Epoch: 4 [85120/189000 (45%)]\tLoss: 6.451711\n",
      "Train Epoch: 4 [85760/189000 (45%)]\tLoss: 6.329955\n",
      "Train Epoch: 4 [86400/189000 (46%)]\tLoss: 6.295545\n",
      "Train Epoch: 4 [87040/189000 (46%)]\tLoss: 6.719102\n",
      "Train Epoch: 4 [87680/189000 (46%)]\tLoss: 6.356654\n",
      "Train Epoch: 4 [88320/189000 (47%)]\tLoss: 6.665724\n",
      "Train Epoch: 4 [88960/189000 (47%)]\tLoss: 6.501444\n",
      "Train Epoch: 4 [89600/189000 (47%)]\tLoss: 7.016479\n",
      "Train Epoch: 4 [90240/189000 (48%)]\tLoss: 6.592070\n",
      "Train Epoch: 4 [90880/189000 (48%)]\tLoss: 6.221639\n",
      "Train Epoch: 4 [91520/189000 (48%)]\tLoss: 6.342219\n",
      "Train Epoch: 4 [92160/189000 (49%)]\tLoss: 6.347627\n",
      "Train Epoch: 4 [92800/189000 (49%)]\tLoss: 6.753981\n",
      "Train Epoch: 4 [93440/189000 (49%)]\tLoss: 6.648220\n",
      "Train Epoch: 4 [94080/189000 (50%)]\tLoss: 6.398361\n",
      "Train Epoch: 4 [94720/189000 (50%)]\tLoss: 6.619887\n",
      "Train Epoch: 4 [95360/189000 (50%)]\tLoss: 6.025770\n",
      "Train Epoch: 4 [96000/189000 (51%)]\tLoss: 6.640273\n",
      "Train Epoch: 4 [96640/189000 (51%)]\tLoss: 6.149923\n",
      "Train Epoch: 4 [97280/189000 (51%)]\tLoss: 6.395762\n",
      "Train Epoch: 4 [97920/189000 (52%)]\tLoss: 6.707821\n",
      "Train Epoch: 4 [98560/189000 (52%)]\tLoss: 6.659656\n",
      "Train Epoch: 4 [99200/189000 (52%)]\tLoss: 5.890487\n",
      "Train Epoch: 4 [99840/189000 (53%)]\tLoss: 6.613774\n",
      "Train Epoch: 4 [100480/189000 (53%)]\tLoss: 6.120192\n",
      "Train Epoch: 4 [101120/189000 (53%)]\tLoss: 6.527058\n",
      "Train Epoch: 4 [101760/189000 (54%)]\tLoss: 6.190530\n",
      "Train Epoch: 4 [102400/189000 (54%)]\tLoss: 6.114064\n",
      "Train Epoch: 4 [103040/189000 (55%)]\tLoss: 6.316389\n",
      "Train Epoch: 4 [103680/189000 (55%)]\tLoss: 6.894905\n",
      "Train Epoch: 4 [104320/189000 (55%)]\tLoss: 6.510680\n",
      "Train Epoch: 4 [104960/189000 (56%)]\tLoss: 6.177882\n",
      "Train Epoch: 4 [105600/189000 (56%)]\tLoss: 5.940846\n",
      "Train Epoch: 4 [106240/189000 (56%)]\tLoss: 6.371307\n",
      "Train Epoch: 4 [106880/189000 (57%)]\tLoss: 6.279194\n",
      "Train Epoch: 4 [107520/189000 (57%)]\tLoss: 6.620558\n",
      "Train Epoch: 4 [108160/189000 (57%)]\tLoss: 6.500492\n",
      "Train Epoch: 4 [108800/189000 (58%)]\tLoss: 6.635211\n",
      "Train Epoch: 4 [109440/189000 (58%)]\tLoss: 6.155494\n",
      "Train Epoch: 4 [110080/189000 (58%)]\tLoss: 6.458070\n",
      "Train Epoch: 4 [110720/189000 (59%)]\tLoss: 6.520504\n",
      "Train Epoch: 4 [111360/189000 (59%)]\tLoss: 6.729423\n",
      "Train Epoch: 4 [112000/189000 (59%)]\tLoss: 6.581892\n",
      "Train Epoch: 4 [112640/189000 (60%)]\tLoss: 6.590405\n",
      "Train Epoch: 4 [113280/189000 (60%)]\tLoss: 6.559066\n",
      "Train Epoch: 4 [113920/189000 (60%)]\tLoss: 6.684669\n",
      "Train Epoch: 4 [114560/189000 (61%)]\tLoss: 7.092374\n",
      "Train Epoch: 4 [115200/189000 (61%)]\tLoss: 6.571846\n",
      "Train Epoch: 4 [115840/189000 (61%)]\tLoss: 6.388018\n",
      "Train Epoch: 4 [116480/189000 (62%)]\tLoss: 6.378949\n",
      "Train Epoch: 4 [117120/189000 (62%)]\tLoss: 6.660388\n",
      "Train Epoch: 4 [117760/189000 (62%)]\tLoss: 6.569099\n",
      "Train Epoch: 4 [118400/189000 (63%)]\tLoss: 6.388310\n",
      "Train Epoch: 4 [119040/189000 (63%)]\tLoss: 6.332515\n",
      "Train Epoch: 4 [119680/189000 (63%)]\tLoss: 6.424273\n",
      "Train Epoch: 4 [120320/189000 (64%)]\tLoss: 6.657211\n",
      "Train Epoch: 4 [120960/189000 (64%)]\tLoss: 6.583615\n",
      "Train Epoch: 4 [121600/189000 (64%)]\tLoss: 6.621774\n",
      "Train Epoch: 4 [122240/189000 (65%)]\tLoss: 6.130284\n",
      "Train Epoch: 4 [122880/189000 (65%)]\tLoss: 6.239254\n",
      "Train Epoch: 4 [123520/189000 (65%)]\tLoss: 6.245798\n",
      "Train Epoch: 4 [124160/189000 (66%)]\tLoss: 6.791045\n",
      "Train Epoch: 4 [124800/189000 (66%)]\tLoss: 6.749835\n",
      "Train Epoch: 4 [125440/189000 (66%)]\tLoss: 6.579391\n",
      "Train Epoch: 4 [126080/189000 (67%)]\tLoss: 6.267918\n",
      "Train Epoch: 4 [126720/189000 (67%)]\tLoss: 6.811546\n",
      "Train Epoch: 4 [127360/189000 (67%)]\tLoss: 6.068342\n",
      "Train Epoch: 4 [128000/189000 (68%)]\tLoss: 6.551978\n",
      "Train Epoch: 4 [128640/189000 (68%)]\tLoss: 6.173144\n",
      "Train Epoch: 4 [129280/189000 (68%)]\tLoss: 6.659079\n",
      "Train Epoch: 4 [129920/189000 (69%)]\tLoss: 6.773747\n",
      "Train Epoch: 4 [130560/189000 (69%)]\tLoss: 6.123485\n",
      "Train Epoch: 4 [131200/189000 (69%)]\tLoss: 6.092136\n",
      "Train Epoch: 4 [131840/189000 (70%)]\tLoss: 6.451325\n",
      "Train Epoch: 4 [132480/189000 (70%)]\tLoss: 6.552034\n",
      "Train Epoch: 4 [133120/189000 (70%)]\tLoss: 6.590171\n",
      "Train Epoch: 4 [133760/189000 (71%)]\tLoss: 6.365057\n",
      "Train Epoch: 4 [134400/189000 (71%)]\tLoss: 6.419303\n",
      "Train Epoch: 4 [135040/189000 (71%)]\tLoss: 6.430009\n",
      "Train Epoch: 4 [135680/189000 (72%)]\tLoss: 6.297994\n",
      "Train Epoch: 4 [136320/189000 (72%)]\tLoss: 6.199782\n",
      "Train Epoch: 4 [136960/189000 (72%)]\tLoss: 6.335283\n",
      "Train Epoch: 4 [137600/189000 (73%)]\tLoss: 6.424958\n",
      "Train Epoch: 4 [138240/189000 (73%)]\tLoss: 6.490365\n",
      "Train Epoch: 4 [138880/189000 (73%)]\tLoss: 6.705770\n",
      "Train Epoch: 4 [139520/189000 (74%)]\tLoss: 6.706606\n",
      "Train Epoch: 4 [140160/189000 (74%)]\tLoss: 6.442456\n",
      "Train Epoch: 4 [140800/189000 (74%)]\tLoss: 6.418842\n",
      "Train Epoch: 4 [141440/189000 (75%)]\tLoss: 6.372782\n",
      "Train Epoch: 4 [142080/189000 (75%)]\tLoss: 6.874662\n",
      "Train Epoch: 4 [142720/189000 (75%)]\tLoss: 6.902268\n",
      "Train Epoch: 4 [143360/189000 (76%)]\tLoss: 6.441236\n",
      "Train Epoch: 4 [144000/189000 (76%)]\tLoss: 6.503592\n",
      "Train Epoch: 4 [144640/189000 (77%)]\tLoss: 6.221214\n",
      "Train Epoch: 4 [145280/189000 (77%)]\tLoss: 6.938760\n",
      "Train Epoch: 4 [145920/189000 (77%)]\tLoss: 6.298173\n",
      "Train Epoch: 4 [146560/189000 (78%)]\tLoss: 7.156964\n",
      "Train Epoch: 4 [147200/189000 (78%)]\tLoss: 6.456655\n",
      "Train Epoch: 4 [147840/189000 (78%)]\tLoss: 6.395531\n",
      "Train Epoch: 4 [148480/189000 (79%)]\tLoss: 6.559131\n",
      "Train Epoch: 4 [149120/189000 (79%)]\tLoss: 6.538042\n",
      "Train Epoch: 4 [149760/189000 (79%)]\tLoss: 6.559118\n",
      "Train Epoch: 4 [150400/189000 (80%)]\tLoss: 6.786684\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m51\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mpytorch_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     test_loss = pytorch_test(model, device, test_loader)\n\u001b[32m      4\u001b[39m     scheduler.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sts_after_images/weela_chess_recreate/src/weela_chess/nick_youtube_tute/../../../sandbox/pytorch_mnist/pytorch_mnist_main.py:45\u001b[39m, in \u001b[36mpytorch_train\u001b[39m\u001b[34m(model, device, train_loader, optimizer, epoch, log_interval)\u001b[39m\n\u001b[32m     43\u001b[39m loss = F.nll_loss(output, target)\n\u001b[32m     44\u001b[39m loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_idx % log_interval == \u001b[32m0\u001b[39m:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mTrain Epoch: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m [\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{:.0f}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m)]\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33mLoss: \u001b[39m\u001b[38;5;132;01m{:.6f}\u001b[39;00m\u001b[33m'\u001b[39m.format(\n\u001b[32m     48\u001b[39m         epoch, batch_idx * \u001b[38;5;28mlen\u001b[39m(data), \u001b[38;5;28mlen\u001b[39m(train_loader.dataset),\n\u001b[32m     49\u001b[39m         \u001b[32m100.\u001b[39m * batch_idx / \u001b[38;5;28mlen\u001b[39m(train_loader), loss.item()))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sts_after_images/weela_chess_recreate/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:130\u001b[39m, in \u001b[36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m opt = opt_ref()\n\u001b[32m    129\u001b[39m opt._opt_called = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sts_after_images/weela_chess_recreate/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:484\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    480\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    481\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    482\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    487\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sts_after_images/weela_chess_recreate/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:89\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     87\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     88\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     91\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sts_after_images/weela_chess_recreate/.venv/lib/python3.12/site-packages/torch/optim/adadelta.py:167\u001b[39m, in \u001b[36mAdadelta.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    143\u001b[39m     (\n\u001b[32m    144\u001b[39m         lr,\n\u001b[32m    145\u001b[39m         rho,\n\u001b[32m   (...)\u001b[39m\u001b[32m    160\u001b[39m         group[\u001b[33m\"\u001b[39m\u001b[33mcapturable\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    161\u001b[39m     )\n\u001b[32m    163\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    164\u001b[39m         group, params_with_grad, grads, square_avgs, acc_deltas, state_steps\n\u001b[32m    165\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43madadelta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43msquare_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m        \u001b[49m\u001b[43macc_deltas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrho\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrho\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sts_after_images/weela_chess_recreate/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:161\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    159\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sts_after_images/weela_chess_recreate/.venv/lib/python3.12/site-packages/torch/optim/adadelta.py:438\u001b[39m, in \u001b[36madadelta\u001b[39m\u001b[34m(params, grads, square_avgs, acc_deltas, state_steps, capturable, foreach, differentiable, has_complex, lr, rho, eps, weight_decay, maximize)\u001b[39m\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    436\u001b[39m     func = _single_tensor_adadelta\n\u001b[32m--> \u001b[39m\u001b[32m438\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m    \u001b[49m\u001b[43msquare_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m    \u001b[49m\u001b[43macc_deltas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrho\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrho\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    446\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    448\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    449\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    450\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sts_after_images/weela_chess_recreate/.venv/lib/python3.12/site-packages/torch/optim/adadelta.py:366\u001b[39m, in \u001b[36m_multi_tensor_adadelta\u001b[39m\u001b[34m(params, grads, square_avgs, acc_deltas, state_steps, lr, rho, eps, weight_decay, maximize, differentiable, capturable, has_complex)\u001b[39m\n\u001b[32m    361\u001b[39m         device_grads = torch._foreach_add(  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[32m    362\u001b[39m             device_grads, device_params, alpha=weight_decay\n\u001b[32m    363\u001b[39m         )\n\u001b[32m    365\u001b[39m torch._foreach_mul_(device_square_avgs, rho)\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_foreach_addcmul_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_square_avgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mrho\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    370\u001b[39m std = torch._foreach_add(device_square_avgs, eps)\n\u001b[32m    371\u001b[39m torch._foreach_sqrt_(std)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 51):\n",
    "    pytorch_train(model, device, train_loader, optimizer, epoch)\n",
    "    test_loss = pytorch_test(model, device, test_loader)\n",
    "    scheduler.step()\n",
    "\n",
    "    if test_loss < best_loss_so_far:\n",
    "        best_model_state = model.state_dict()\n",
    "        best_loss_so_far = test_loss\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter > patience:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b41351",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model_state, \"torch_chess_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e65a61",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a04b39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"torch_chess_model.pt\", weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5d4d69",
   "metadata": {},
   "source": [
    "## Play a Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eaa3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_move(model, board, int_to_move):\n",
    "    board_matrix = board_to_matrix(board).reshape(1, 8, 8, 12)\n",
    "    predictions = model.predict(board_matrix)[0]\n",
    "    legal_moves = list(board.legal_moves)\n",
    "    legal_moves_uci = [move.uci() for move in legal_moves]\n",
    "    sorted_indices = np.argsort(predictions)[::-1]\n",
    "    for move_index in sorted_indices:\n",
    "        move = int_to_move[move_index]\n",
    "        if move in legal_moves_uci:\n",
    "            return move\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716ba5c1",
   "metadata": {},
   "source": [
    "transport, engine = await chess.engine.popen_uci(\"/home/gerk/sts_after_images/weela_chess_recreate/sandbox/stockfish/stockfish-ubuntu-x86-64-avx2\")\n",
    "await engine.configure({\"Skill Level\": 1})\n",
    "\n",
    "# +\n",
    "async def stockfish_game_iter():\n",
    "    board = Board()\n",
    "    limit = chess.engine.Limit(time=0.1)\n",
    "\n",
    "    while not board.is_game_over():\n",
    "        next_move = predict_next_move(model, board, int_to_move)\n",
    "        board.push_uci(next_move)\n",
    "        yield board\n",
    "\n",
    "        #pshhh, as if\n",
    "        if board.is_game_over():\n",
    "            break\n",
    "\n",
    "        next_stockfish_move = await engine.play(board, limit)\n",
    "        board.push(next_stockfish_move.move)\n",
    "        yield board\n",
    "\n",
    "stockfish_game = stockfish_game_iter()\n",
    "# -\n",
    "\n",
    "next_move = await stockfish_game.__anext__()\n",
    "next_move"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
